[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Project portfolio",
    "section": "",
    "text": "Mapping suitable nesting habitat for an endangered bird in the SCM\n\n\n\nGeospatial-analysis\n\n\nMESM\n\n\nConservation-planning\n\n\nRStudio\n\n\n\nDelineating suitable nesting habitat for marbled murrelets following severe wildfires in the Santa Cruz Mountains (SCM)\n\n\n\nMaxwell Pepperdine\n\n\nJan 16, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApplying supervised machine mearning to landuse cover in Santa Barbara, CA\n\n\n\nMachine-learning\n\n\nMESM\n\n\nRemote-sensing\n\n\nRStudio\n\n\n\nBuilding algorithms with machine learning to understand how we use our land\n\n\n\nMaxwell Pepperdine\n\n\nNov 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMarine aquacultire suitability on the West Coast\n\n\n\nGeospatial-analysis\n\n\nMESM\n\n\nRStudio\n\n\n\nBuilding reproducible workflows to model aquaculture habitat through spatial analysis\n\n\n\nMaxwell Pepperdine\n\n\nNov 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigating EJ implications of the Houston blackout\n\n\n\nGeospatial-analysis\n\n\nMESM\n\n\nRStudio\n\n\n\nA spatial analysis of the Houston blackout and affected communities\n\n\n\nMaxwell Pepperdine\n\n\nNov 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring patterns of environmental justice in Los Angeles County\n\n\n\nGeospatial-analysis\n\n\nMESM\n\n\nRStudio\n\n\n\nA spatial analysis to analyze the legacy of historical redlining in Los Angeles County\n\n\n\nMaxwell Pepperdine\n\n\nNov 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMapping the distribution of native and invasive marine species in the Indo-Pacific region\n\n\n\nMaxEnt\n\n\nMESM\n\n\nConservation-planning\n\n\nRStudio\n\n\n\nUsing MaxEnt to model current and future distributions of grape coral and crown-of-thorn starfish\n\n\n\nMaxwell Pepperdine & Zoe Zhou\n\n\nSep 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInforming reserve design in the Morro Bay Watershed\n\n\n\nPrioritizR\n\n\nMESM\n\n\nConservation-planning\n\n\nRStudio\n\n\n\nReserve design in the Morro Bay watershed prioritizing special status species\n\n\n\nMaxwell Pepperdine\n\n\nSep 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring habitat connectivity between core areas in a Costa Rican landscape\n\n\n\nGeospatial-analysis\n\n\nMESM\n\n\nConservation-planning\n\n\nArcGIS Pro\n\n\n\nModeling movement patterns and connectivity for the jaguar (Panthera onca) across southern Costa Rica with Circuitscape\n\n\n\nMaxwell Pepperdine\n\n\nSep 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalyzing the impacts of hurricanes upon bathymetry\n\n\n\nGeospatial-analysis\n\n\nMESM\n\n\nRemote-sensing\n\n\nPython\n\n\n\nQuantifying and mapping bathymetric changes surrounding the Grand Bahama & Great Abaco islands due to Hurricane Dorian\n\n\n\nMaxwell Pepperdine\n\n\nSep 10, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-11-20-aquaculture/index.html",
    "href": "posts/2024-11-20-aquaculture/index.html",
    "title": "Marine aquacultire suitability on the West Coast",
    "section": "",
    "text": "Show packages used in this analysis\nlibrary(tidyverse)\nlibrary(here)\nlibrary(sf)\nlibrary(terra)\nlibrary(tmap)\nlibrary(patchwork)"
  },
  {
    "objectID": "posts/2024-11-20-aquaculture/index.html#load-packages",
    "href": "posts/2024-11-20-aquaculture/index.html#load-packages",
    "title": "Marine aquacultire suitability on the West Coast",
    "section": "",
    "text": "Show packages used in this analysis\nlibrary(tidyverse)\nlibrary(here)\nlibrary(sf)\nlibrary(terra)\nlibrary(tmap)\nlibrary(patchwork)"
  },
  {
    "objectID": "posts/2024-11-20-aquaculture/index.html#background",
    "href": "posts/2024-11-20-aquaculture/index.html#background",
    "title": "Marine aquacultire suitability on the West Coast",
    "section": "Background",
    "text": "Background\nWith an ever growing human population, marine aquaculture has the potential to play a significant role global food supply, and is a more sustainable option than land-based meat production (Hall et al., 2011). A study that mapped the global potential for marine aquaculture based on multiple constraints (e.g., ship traffic, dissolved oxygen, bottom depth) found that global seafood demand could be met using less than 0.015% of the global ocean area (Gentry et al., 2017).\nThis analysis aims to determine which Exclusive Economic Zones (EEZ) on the West Coast of the US are best suited to develop marine aquaculture for several species of oysters and Pacific littleneck clams (Leukoma staminea),two of the most common species farmed in marine aquaculture on the West Coast. Suitable growing locations were determined based on range of suitable sea surface temperature (SST) and depth values for each species listed below. Oyster conditions were provided in the assignment description, and suitable temperatures and depths for the littleneck clam were selected based on Shaw (1986) and Harbo (1997). Suitable growing areas for oysters were found first, and then the workflow was made generalizable by transforming into a function that could be used to find suitable growing areas for any marine aquaculture species on the West Coast based on ocean depth and SST.\nSuitable growing conditions for oysters:\n\nsea surface temperature: 11-30°C\ndepth: 0-70 meters below sea level\n\nSuitable growing conditions for the Pacific littleneck clam:\n\nsea surface temperature: 0-25°C\ndepth: 0-46 meters below sea level"
  },
  {
    "objectID": "posts/2024-11-20-aquaculture/index.html#data-description",
    "href": "posts/2024-11-20-aquaculture/index.html#data-description",
    "title": "Marine aquacultire suitability on the West Coast",
    "section": "Data description",
    "text": "Data description\n\nSea surface temperature (SST)\nAnnual sea surface temperature (SST) from the years 2008 to 2012 were used to characterize the average SST within the region. This data was originally generated from NOAA’s 5km Daily Global Satellite Sea Surface Temperature Anomaly v3.1.\nData files:\n\naverage_annual_sst_2008.tif\naverage_annual_sst_2009.tif\naverage_annual_sst_2010.tif\naverage_annual_sst_2011.tif\naverage_annual_sst_2012.tif\n\n\n\nBathyemtry\nBathymetric data was sourced from General Bathymetric Chart of the Oceans (GEBCO) to characterize the depth of the ocean (m below sea level).\nData file: depth.tif\n\n\nExclusive Economic Zones (EEZ)\nMaritime boundaries were designated using Exclusive Economic Zones (EEZs) off of the west coast of US from Marine Regions.\nData file: wc_regions_clean.shp\n\n\nU.S. states & territories\nBoundaries for all U.S. states and territories, included for context in the maps, were sourced from NOAA’s national GIS program.\nData file: s_05mr24.shp"
  },
  {
    "objectID": "posts/2024-11-20-aquaculture/index.html#analysis",
    "href": "posts/2024-11-20-aquaculture/index.html#analysis",
    "title": "Marine aquacultire suitability on the West Coast",
    "section": "Analysis",
    "text": "Analysis\nPseudo code/outline:\n\nPrepare data. Load all necessary data, combine the SST data into a raster stack, and make sure they’re all in the same CRS. If not, transform everything to WGS 84 (EPSG:4326).\nProcess data. Find the mean SST from 2008-2012, convert it from Kelvin to Celsius, resample the bathymetry raster to match the resolution, extent, and position of the SST raster, and crop the depth raster to match the extent of the SST raster.\nFind suitable locations. Determine which locations meet the suitable growing conditions for oysters only before expanding the workflow to other species. To do this, we first need to reclassify the bathymetry and SST rasters to either NA (unsuitable), or 1 (suitable). These rasters were then multiplied by each other to isolate areas that meet suitable conditions for both depth and SST.\nDetermine the most suitable EEZ. Calculate the amount of suitable area for each EEZ region to rank zones by priority. To do this, rasterize the EEZ shapefile, mask it to the suitable locations, calculate the area of each cell in the raster, and sum the area of suitable locations in each EEZ. Lastly, join the area data back to the EEZ shapefile and make some visualizations.\nCreate a reproducible workflow for other species. After finding locations with suitable growing conditions for oysters, this workflow was transformed into a function that could isolate suitable growing conditions for any marine aquaculture species on the West Coast based on ocean depth and SST. The function has the following characteristics:\n\n\narguments:\n\nminimum and maximum sea surface temperature\nminimum and maximum depth\nspecies name\n\noutputs:\n\nmap of EEZ regions colored by amount of suitable area\n\n\n\nTest the function for the Pacific littleneck clam! The function was tested for the Pacific littleneck clam using the species-specific growing conditions described above.\n\n\nLoad data\nWe want to load the SST data as a raster stack to make it easier to generate a mean SST raster for the years 2008-2012.\n\n\nShow the code\n# shapefile for West Coast EEZ\nwc_eez &lt;- st_read(here(\"posts/2024-11-20-aquaculture/data/wc_regions_clean.shp\"))\n\n# bathymetry raster\nbathy &lt;- rast(here(\"posts/2024-11-20-aquaculture/data/depth.tif\"))\n\n# SST rasters\nsst_2008 &lt;- rast(here(\"posts/2024-11-20-aquaculture/data/average_annual_sst_2008.tif\"))\nsst_2009 &lt;- rast(here(\"posts/2024-11-20-aquaculture/data/average_annual_sst_2009.tif\"))\nsst_2010 &lt;- rast(here(\"posts/2024-11-20-aquaculture/data/average_annual_sst_2010.tif\"))\nsst_2011 &lt;- rast(here(\"posts/2024-11-20-aquaculture/data/average_annual_sst_2011.tif\"))\nsst_2012 &lt;- rast(here(\"posts/2024-11-20-aquaculture/data/average_annual_sst_2012.tif\"))\n\n# SST raster stack \nsst_stack &lt;- c(sst_2008, sst_2009, sst_2010, sst_2011, sst_2012)\n#plot(sst_stack)\n\n\n\n\nCheck the CRS of each dataset & transform to WGS 84 if they don’t match\n\n\nShow the code\n# # check if each dataset has the same CRS\n# crs(wc_eez) == crs(bathy)\n# crs(wc_eez) == crs(sst_stack)\n# crs(bathy) == crs(sst_stack)\n\n# none are in the same CRS; transform all to WGS 84\nbathy &lt;- project(bathy, \n                 \"EPSG:4326\")\nsst_stack &lt;- project(sst_stack, \n                     \"EPSG:4326\")\nwc_eez &lt;- st_transform(wc_eez, \n                       crs = st_crs(bathy))\n\n# check if they are now in the same CRS\nif(crs(wc_eez) == crs(bathy) & crs(wc_eez) == crs(sst_stack)) {\n  print(\"Carry on! All datasets are now in the same CRS\") \n} else {\n  warning(\"STOP! Datasets are not in the same CRS\")\n}\n\n\n[1] \"Carry on! All datasets are now in the same CRS\"\n\n\n\n\nProcess data\nTo prepare the data for the growing suitability analysis, we found the mean SST from 2008-2012, converted it from Kelvin to Celsius, resampled the bathymetry raster to match the resolution, extent, and position of the SST raster using the nearest neighbor method, and cropped the depth raster to match the extent of the SST raster.\n\n\nShow the code\n# find the mean SST from 2008-2012\n# create a single raster of average SST\nsst_mean &lt;- mean(sst_stack)\n# plot(sst_mean) # QC to make sure this created one raster\n\n\n# convert average SST from Kelvin to Celsius\n# subtract 273.15 from each grid cell in the raster\nsst_mean_celsius &lt;- sst_mean - 273.15\n# plot(sst_mean_celsius) # QC to make sure this worked\n\n\n# resample the bathy raster \n# match the resolution, extent, and position of the SST raster\nbathy_resample &lt;- resample(bathy, \n                           sst_mean_celsius, \n                           method = \"near\")\n\n\n# crop & mask the depth raster to match the extent of the SST raster \nbathy_crop &lt;- crop(bathy_resample, \n                   sst_mean_celsius, \n                   mask = TRUE)\n\n\n\n\nQC: Check that the depth & SST data match in resolution, extent, and CRS\n\n\nShow the code\n# resolution \nif(all(res(bathy_crop) == res(sst_mean_celsius))) {\n  print(\"The bathy and SST data have the same resolution.\")\n} else {\n  warning(\"STOP! Resolution does not match.\")\n}\n\n\n[1] \"The bathy and SST data have the same resolution.\"\n\n\nShow the code\n# extent\nif(ext(bathy_crop) == ext(sst_mean_celsius)) {\n  print(\"The bathy and SST data have the same extent.\")\n} else {\n  warning(\"STOP! The bathy and SST raster do not have the same extent.\")\n}\n\n\n[1] \"The bathy and SST data have the same extent.\"\n\n\nShow the code\n# CRS\nif(crs(bathy_crop) == crs(sst_mean_celsius)) {\n  print(\"The bathy and SST data have the same CRS.\")\n} else {\n  warning(\"STOP! The bathy and SST data do not have the same CRS.\")\n}\n\n\n[1] \"The bathy and SST data have the same CRS.\"\n\n\n\n\nPlot the bathymetric and SST data\n\n\nShow the code\n# load US states for context \nus_states &lt;- st_read(here(\"posts/2024-11-20-aquaculture/data/us_states/s_05mr24.shp\"), \n                     quiet = TRUE) %&gt;% \n  filter(STATE %in% c(\"WA\", \"CA\", \"OR\", \"NV\", \"ID\"))\nus_states &lt;- st_make_valid(us_states) %&gt;% \n  st_transform(crs = st_crs(wc_eez))\n\nbathy_map &lt;- tm_grid(lines = FALSE) + \ntm_shape(us_states) +\n  tm_polygons(col = \"grey\",\n              alpha = 0.2,\n              border.col = \"black\") +\ntm_shape(bathy_crop, \n         is.master = TRUE) + \n  tm_raster(palette = \"Blues\", \n            breaks = c(-4000, -2000, -1000, -500, -100, -50, 0), \n            title = \"Bathymetry (m)\") + \ntm_shape(wc_eez) + \n  tm_borders(col = \"black\", \n              lwd = 1.5) + \n  tm_text(\"rgn_key\", size = 0.7, col = \"black\") +\n  tm_layout(legend.outside = TRUE, \n            frame = TRUE)\nbathy_map\n\n\n\n\n\n\n\n\nFigure 1: Bathymetric (m below sea level) data for the West Coast of the US used in the analysis. West Coast Exclusive Economic Zones (EEZ) are outlined in black. WA = Washington, OR = Oregon, CA-N = northern California, CA-C = central California, and CA-S = southern California.\n\n\n\n\n\n\n\nShow the code\nsst_map &lt;- tm_grid(lines = FALSE) +\ntm_shape(us_states) +\n  tm_polygons(col = \"grey\",\n              alpha = 0.2,\n              border.col = \"black\") +\ntm_shape(sst_mean_celsius, \n         is.master = TRUE) + \n  tm_raster(palette = \"viridis\", \n            style = \"cont\", \n            title = \"Sea Surface Temperature (°C)\") +\ntm_shape(wc_eez) +\n  tm_borders(col = \"black\", \n              lwd = 1.5) + \n  tm_text(\"rgn_key\", size = 0.7, col = \"white\") +\n  tm_layout(legend.outside = TRUE, \n            frame = TRUE)\nsst_map\n\n\n\n\n\n\n\n\nFigure 2: Sea surface temperature (SST) (°C) data for the West Coast of the US used in the analysis. West Coast Exclusive Economic Zones (EEZ) are outlined in black. WA = Washington, OR = Oregon, CA-N = northern California, CA-C = central California, and CA-S = southern California.\n\n\n\n\n\n\n\nFind suitable locations for oysters\nSuitable growing conditions for oysters are defined as follows:\n\nsea surface temperature: 11-30°C\ndepth: 0-70 meters below sea level\n\nTo find suitable locations for oysters, we reclassified the SST and depth data into locations that meet the suitable growing conditions for oysters. Suitable areas we defined as 1, and unsuitable areas were assigned NA values. We then used map algebra to multiply the reclassified rasters together to find locations that meet the suitable growing conditions for both depth and SST. If either of these environmental variables’ suitable conditions were not met, the location was assigned a value of NA and considered unsuitable.\n\n\nShow the code\n# define SST reclassification matrix\nrcl_sst &lt;- matrix(c(-Inf, 11, NA, \n                    11, 30, 1, \n                    30, Inf, NA), \n                  ncol = 3, \n                  byrow = TRUE)\n# define depth reclassification matrix\nrcl_depth &lt;- matrix(c(-Inf, -70, NA, \n                      -70, 0, 1, \n                      0, Inf, NA), \n                    ncol = 3, \n                    byrow = TRUE)\n\n# reclassify SST and depth data into locations that are suitable for oysters\nsst_reclass &lt;- classify(sst_mean_celsius, \n                        rcl_sst)\nbathy_reclass &lt;- classify(bathy_crop, \n                          rcl_depth)\n\n\n\n# find locations that meet the suitable growing conditions for oysters\n# values of 1 indicate suitable locations for both depth and SST!\noyster_suitable &lt;-  sst_reclass * bathy_reclass\n# plot(oyster_suitable)\n\n\n\n\nDetermine the most suitable EEZ\nTo determine the most suitable EEZ for oysters, we calculated the total area of suitable growing locations in each EEZ region. We first rasterized the EEZ shapefile to mask it to the suitable locations for oysters. Then, we calculated the area of each cell in the raster using the terra::cellSize() function and summed the area of suitable locations in each EEZ with terra::zonal(). Lastly, we joined the area data back to the EEZ shapefile by rgn and calculated the percent of each EEZs total area that has suitable growing areas for oysters.\n\n\nShow the code\n# rasterize the EEZ shapefile\nwc_eez_rast &lt;- rasterize(wc_eez, \n                         oyster_suitable, \n                         field = \"rgn\")\n# plot(wc_eez_rast) # QC\n\n# crop & mask it to the suitable locations for oysters\nwc_eez_suitable &lt;- crop(wc_eez_rast, \n                        oyster_suitable, \n                        mask = TRUE)\n\n# find the area covered by each cell in the masked EEZ raster\ncell_area &lt;- cellSize(wc_eez_suitable, \n                      unit = \"km\")\n\n# calculate the area of suitable locations for oysters in each EEZ\nsuitable_area &lt;- zonal(cell_area, \n                       wc_eez_suitable, # define the zones to calc area in \n                       fun = \"sum\", \n                       na.rm = TRUE)\n\n# join the area data back to the EEZ shapefile\nwc_eez_joined &lt;- left_join(wc_eez, suitable_area, \n                           by = \"rgn\") %&gt;% \n  rename(suitable_area_km2 = area) %&gt;% \n  select(rgn, rgn_key, area_km2, suitable_area_km2) %&gt;% \n  mutate(percent_suitable = suitable_area_km2 / area_km2 * 100)\n\n\n\n\nVisualize the results\nTo visualize the results, we made two figures: (1) a map of EEZ regions colored by the amount of suitable area (km^2) for oysters; (2) two bar plots to show the total suitable area (km^2) and the percent of each EEZs total area that has suitable growing areas for oysters.\n\n\nShow the code\ntm_grid(lines = FALSE) +\ntm_shape(us_states) +\n  tm_polygons(col = \"grey\",\n              alpha = 0.2,\n              border.col = \"black\") + \ntm_shape(wc_eez_joined, \n         is.master = TRUE) + \n  tm_polygons(col = \"suitable_area_km2\", \n              palette = \"Greens\", \n              title = \"Amount of suitable area (km^2)\", \n              style = \"cat\") + \n  tm_text(\"rgn_key\", size = 0.7, col = \"black\") + \ntm_shape(wc_eez_suitable) + \n    tm_raster(palette = \"black\", \n              legend.show = FALSE) +\n  tm_add_legend(type = \"fill\", \n                labels = \" \", \n                col = \"black\", \n                title = \"Suitable growing areas\") +\n  tm_layout(legend.outside = TRUE, \n            frame = TRUE, \n            main.title = \"Suitable growing area for oysters in West Coast EEZs\", \n            main.title.size = 1.3)\n\n\n\n\n\n\n\n\nFigure 3: Exclusive Economic Zones (EEZ) on the West Coast of the US colored by the amount of suitable area for oysters in each zone (km^2). WA = Washington, OR = Oregon, CA-N = northern California, CA-C = central California, and CA-S = southern California. The black areas show the delineated suitable growing areas for oysters that were summed.\n\n\n\n\n\n\n\nShow the code\nplot1 &lt;- ggplot(wc_eez_joined, \n                aes(x = rgn_key, \n                    y = suitable_area_km2)) + \n  geom_bar(stat = \"identity\", \n           fill = \"seagreen3\", \n           col = \"black\") + \n  labs(title = \" \", \n       x = \"EEZ\", \n       y = \"Suitable area (km^2)\") + \n  theme_minimal() + \n  theme(axis.text.x = element_text(angle = 45, \n                                   hjust = 1))\n#plot1\n\nplot2 &lt;- ggplot(wc_eez_joined, \n                aes(x = rgn_key, \n                    y = percent_suitable)) + \n  geom_bar(stat = \"identity\", \n           fill = \"seagreen4\", \n           col = \"black\") + \n  labs(title = \" \", \n       x = \"EEZ\", \n       y = \"% suitable growing areas\") + \n  theme_minimal() + \n  theme(axis.text.x = element_text(angle = 45, \n                                   hjust = 1))\n#plot2\n\ncombined_plots &lt;- plot1 + plot2\ncombined_plots &lt;- combined_plots + plot_annotation(tag_levels = \"A\")\ncombined_plots\n\n\n\n\n\n\n\n\nFigure 4: Amount of suitable area for oysters in each Exclusive Economic Zone (EEZ) on the West Coast of the US. (A) Shows the total suitable area in km^2, and (B) shows the percent of each EEZs total area that has suitable growing areas for oysters. WA = Washington, OR = Oregon, CA-N = northern California, CA-C = central California, and CA-S = southern California."
  },
  {
    "objectID": "posts/2024-11-20-aquaculture/index.html#make-workflow-generalizable",
    "href": "posts/2024-11-20-aquaculture/index.html#make-workflow-generalizable",
    "title": "Marine aquacultire suitability on the West Coast",
    "section": "Make workflow generalizable",
    "text": "Make workflow generalizable\nNow that we have a workflow to find suitable growing areas for oysters, we can transform this workflow into a function that can be used to find suitable growing areas for any marine aquaculture species on the West Coast based on ocean depth and SST!\n\n\nShow the code\n# function to find suitable locations for any marine aquaculture species\nideal_growing_conditions &lt;- function(species, depth_min, depth_max, \n                                     sst_min, sst_max){\n  \n  ################ reclassification to find suitable habitat ################\n  \n  # define SST reclassification matrix\n  rcl_sst &lt;- matrix(c(-Inf, sst_min, NA, \n                      sst_min, sst_max, 1, \n                      sst_max, Inf, NA), \n                    ncol = 3, \n                    byrow = TRUE) \n  # define depth reclassification matrix\n  rcl_depth &lt;- matrix(c(-Inf, depth_max, NA, \n                        depth_max, depth_min, 1, \n                        depth_min, Inf, NA), \n                      ncol = 3, \n                      byrow = TRUE)\n  \n  \n  # reclassify SST data into suitable locations \n  sst_reclass &lt;- classify(sst_mean_celsius, \n                          rcl_sst) \n  # reclassify depth data into suitable locations\n  bathy_reclass &lt;- classify(bathy_crop, \n                            rcl_depth)\n  \n  \n  # find locations that meet the suitable growing conditions\n  suitable_locations &lt;-  sst_reclass * bathy_reclass\n  \n  \n  ##################### finding the most suitable EEZ #####################\n  \n  # rasterize the EEZ shapefile\n  wc_eez_rast &lt;- rasterize(wc_eez, \n                           suitable_locations, \n                           field = \"rgn\")\n  \n  # crop & mask it to the suitable locations\n  wc_eez_suitable &lt;- crop(wc_eez_rast, \n                          suitable_locations, \n                          mask = TRUE)\n  \n  # find the area of each cell in the masked EEZ raster\n  cell_area &lt;- cellSize(wc_eez_suitable, \n                        unit = \"km\")\n  \n  # calculate the area of suitable locations in each EEZ\n  suitable_area &lt;- zonal(cell_area, \n                         wc_eez_suitable, \n                         fun = \"sum\", \n                         na.rm = TRUE)\n  \n  # join the area data back to the EEZ shapefile\n  wc_eez_joined &lt;- left_join(wc_eez, \n                             suitable_area, \n                             by = \"rgn\") %&gt;% \n    rename(suitable_area_km2 = area) %&gt;% \n    select(rgn, rgn_key, area_km2, suitable_area_km2) %&gt;% \n    mutate(percent_suitable = suitable_area_km2 / area_km2 * 100)\n  \n  \n  ##################### mapping the results #####################\n  \n  # map of EEZ regions colored by the amount of suitable area\n  \n  tm_grid(lines = FALSE) + \n  tm_shape(us_states) +\n  tm_polygons(col = \"grey\",\n              alpha = 0.2,\n              border.col = \"black\") +\n  tm_shape(wc_eez_joined, \n           is.master = TRUE) + \n    tm_polygons(col = \"suitable_area_km2\", \n                palette = \"Greens\", \n                title = \"Amount of suitable area (km^2)\", \n                style = \"cat\") + \n    tm_text(\"rgn_key\", size = 0.7, col = \"black\") +\n  tm_shape(wc_eez_suitable) + \n    tm_raster(palette = \"black\", \n              legend.show = FALSE) +\n  tm_add_legend(type = \"fill\", \n                labels = \" \", \n                col = \"black\", \n                title = \"Suitable growing areas\") +\n    tm_layout(legend.outside = TRUE, \n              frame = TRUE, \n              main.title = paste(\"Suitable growing area for\", species, \n                            \"in West Coast EEZs\"), \n              main.title.size = 1.2)\n  \n}\n\n\n\nTest the function for the Pacific littleneck clam\n\n\nShow the code\n# test the function with the Pacific littleneck clam's growing conditions\nideal_growing_conditions(species = \"Pacific littleneck clams\", \n                         depth_min = 0, \n                         depth_max = -46, \n                         sst_min = 0, \n                         sst_max = 25)\n\n\n\n\n\n\n\n\nFigure 5: Amount of suitable area for the Pacific littleneck clam in each Exclusive Economic Zone (EEZ) on the West Coast of the US. (A) Shows the total suitable area in km^2, and (B) shows the percent of each EEZ’s area that has suitable growing conditions."
  },
  {
    "objectID": "posts/2024-11-20-aquaculture/index.html#reflection",
    "href": "posts/2024-11-20-aquaculture/index.html#reflection",
    "title": "Marine aquacultire suitability on the West Coast",
    "section": "Reflection",
    "text": "Reflection\nLooking at Figure 4, we can see that the central California EEZ (CA-C) has the greatest area of suitable growing locations for oysters based on SST and depth, and the Washington EEZ has the greatest percentage of suitable growing locations compared to the EEZs total area. Looking at Figure 5, we can see that the Washington EEZ has both the greatest area of suitable growing locations and the greatest percentage of suitable growing locations for the Pacific littleneck clam.\nAs the human population continues to grow, the demand for seafood is expected to increase. Marine aquaculture has the potential to play a significant role in meeting this demand, and is a more sustainable option than land-based meat production. This analysis aimed to determine which Exclusive Economic Zones (EEZ) on the West Coast of the US are best suited to develop marine aquaculture for several species of oysters and the Pacific littleneck clam. We only considered two species and two variables driving suitable growing conditions in this analysis, but the workflow can be easily adapted to other species and additional predictor variables to create more robust suitability modeling."
  },
  {
    "objectID": "posts/2024-11-20-aquaculture/index.html#references",
    "href": "posts/2024-11-20-aquaculture/index.html#references",
    "title": "Marine aquacultire suitability on the West Coast",
    "section": "References",
    "text": "References\nFlanders Marine Institute (2023). Maritime Boundaries Geodatabase: Maritime Boundaries and Exclusive Economic Zones (200NM), version 12. Available online at https://www.marineregions.org/. https://doi.org/10.14284/632\nGEBCO Compilation Group (2024) GEBCO 2024 Grid (doi:10.5285/1c44ce99-0a0d-5f4f-e063-7086abc0ea0f)\nGentry, R. R., Froehlich, H. E., Grimm, D., Kareiva, P., Parke, M., Rust, M., Gaines, S. D., & Halpern, B. S. Mapping the global potential for marine aquaculture. Nature Ecology & Evolution, 1, 1317-1324 (2017).\nHall, S. J., Delaporte, A., Phillips, M. J., Beveridge, M. & O’Keefe, M. Blue Frontiers: Managing the Environmental Costs of Aquaculture (The WorldFish Center, Penang, Malaysia, 2011).\nHarbo, R. M. (1997). Shells & shellfish of the Pacific northwest: a field guide. Madiera Park, BC: Harbour Publishing.\nNOAA Coral Reef Watch. 2019, updated daily. NOAA Coral Reef Watch Version 3.1 Daily 5km Satellite Regional Virtual Station Time Series Data for Southeast Florida, Mar. 12, 2013-Mar. 11, 2014. College Park, Maryland, USA: NOAA Coral Reef Watch. Data set accessed at https://coralreefwatch.noaa.gov/product/vs/data.php.\nShaw, W N. (1986) Species profiles: life histories and environmental requirements of coastal fishes and invertebrates (Pacific Southwest): Common littleneck clam. Protothaca staminea. United States."
  },
  {
    "objectID": "posts/2024-11-10-houston-blackout/index.html",
    "href": "posts/2024-11-10-houston-blackout/index.html",
    "title": "Investigating EJ implications of the Houston blackout",
    "section": "",
    "text": "The frequency and intensity of extreme weather events are increasing due to climate change, bringing devastating impacts. “In February 2021, the state of Texas suffered a major power crisis, which came about as a result of three severe winter storms sweeping across the United States on February 10–11, 13–17, and 15–20” (Wikipedia, 2021).\nThis analysis will identify the impacts of these extreme winter storms by estimating the number of homes that lost power throughout the Houston metropolitan area, and examine whether or not these impacts were distributed equitably across census tracts based on their median income levels. Remotely-sensed night lights data, acquired from the Visible Infrared Imaging Radiometer Suite (VIIRS) onboard the Suomi satellite, serve as the basis for this analysis. Specifically, we used the VNP46A1 to detect differences in nighttime lights before and after the winter storms, allowing the identification of areas that lost electric power.\nTo determine the number of homes that lost power, these areas identified with the VIIRS data were linked to OpenStreetMap (OSM) data on buildings and road. These analyses were then linked with data from the US Census Bureau to investigate the correlation between socioeconomic factors and recovery."
  },
  {
    "objectID": "posts/2024-11-10-houston-blackout/index.html#backgroundoverview",
    "href": "posts/2024-11-10-houston-blackout/index.html#backgroundoverview",
    "title": "Investigating EJ implications of the Houston blackout",
    "section": "",
    "text": "The frequency and intensity of extreme weather events are increasing due to climate change, bringing devastating impacts. “In February 2021, the state of Texas suffered a major power crisis, which came about as a result of three severe winter storms sweeping across the United States on February 10–11, 13–17, and 15–20” (Wikipedia, 2021).\nThis analysis will identify the impacts of these extreme winter storms by estimating the number of homes that lost power throughout the Houston metropolitan area, and examine whether or not these impacts were distributed equitably across census tracts based on their median income levels. Remotely-sensed night lights data, acquired from the Visible Infrared Imaging Radiometer Suite (VIIRS) onboard the Suomi satellite, serve as the basis for this analysis. Specifically, we used the VNP46A1 to detect differences in nighttime lights before and after the winter storms, allowing the identification of areas that lost electric power.\nTo determine the number of homes that lost power, these areas identified with the VIIRS data were linked to OpenStreetMap (OSM) data on buildings and road. These analyses were then linked with data from the US Census Bureau to investigate the correlation between socioeconomic factors and recovery."
  },
  {
    "objectID": "posts/2024-11-10-houston-blackout/index.html#data-description",
    "href": "posts/2024-11-10-houston-blackout/index.html#data-description",
    "title": "Investigating EJ implications of the Houston blackout",
    "section": "Data description",
    "text": "Data description\n\nNight lights\nAs mentioned above, this analysis uses night light data acquired from the Visible Infrared Imaging Radiometer Suite (VIIRS). VIIRS data is distributed through NASA’s Level-1 and Atmospheric Archive & Distribution System Distributed Active Archive Center (LAADS DAAC). Many NASA Earth data products are distributed in 10x10 degree tiles in sinusoidal equal-area projection, and tiles are identified by their horizontal and vertical position in the grid. Houston lies on the border of tiles h08v05 and h08v06, so we need to download two files per date to cover the entire Houston area, as described below.\nData files:\n\nVNP46A1.A2021038.h08v05.001.2021039064328.tif: tile h08v05, collected on 2021-02-07\nVNP46A1.A2021038.h08v06.001.2021039064329.tif: tile h08v06, collected on 2021-02-07\nVNP46A1.A2021047.h08v05.001.2021048091106.tif: tile h08v05, collected on 2021-02-16\nVNP46A1.A2021047.h08v06.001.2021048091105.tif: tile h08v06, collected on 2021-02-16\n\n\n\nRoads\nBecause highways typically account for a large portion of night lights observable from space, we need to exclude them from the analysis to avoid falsely identifying areas with reduced traffic as areas without power. OpenStreetMap (OSM) is a collaborative project that creates publicy avialable geographic data; however, because it covers global extents, organizing this data into a database where it can be subsetted and processed is a large undertaking. Thankfully, third party companies such as Geofabrik’s redistribute OSM. We used this site to retrieve a shapefile of all highways in Texas and then subset this data to only include roads intersecting the Houston metropolitan area.\nData file\n\ngis_osm_roads_free_1.gpkg: OpenStreetMap data for roads in Texas\n\n\n\nHouses\nOSM also provides building data, which again was downloaded from Geofabrik and subset to only include houses in the Houston metropolitan area.\nData file\n\ngis_osm_buildings_a_free_1.gpkg: OpenStreetMap data for buildings in Texas\n\n\n\nSocioeconomic\nWe obtained data from the U.S. Census Bureau’s American Community Survey (ACS) for 2019. This data is distributed in a file geodatabase format, which contains both the geometry of census tracts and layers that contain a subset of the fields documents in the ACS metadata.\nData file\n\nACS_2019_5YR_TRACT_48_TEXAS.gdb: ACS data for Texas"
  },
  {
    "objectID": "posts/2024-11-10-houston-blackout/index.html#load-packages",
    "href": "posts/2024-11-10-houston-blackout/index.html#load-packages",
    "title": "Investigating EJ implications of the Houston blackout",
    "section": "Load packages",
    "text": "Load packages\n\n\nShow packages used in this analysis\nlibrary(sf)\nlibrary(terra)\nlibrary(stars)\nlibrary(tmap)\nlibrary(tmaptools)\nlibrary(tidyverse)\nlibrary(here)\nlibrary(patchwork)"
  },
  {
    "objectID": "posts/2024-11-10-houston-blackout/index.html#part-1-find-locations-that-experienced-a-blackout-by-creating-a-mask",
    "href": "posts/2024-11-10-houston-blackout/index.html#part-1-find-locations-that-experienced-a-blackout-by-creating-a-mask",
    "title": "Investigating EJ implications of the Houston blackout",
    "section": "Part 1: Find locations that experienced a blackout by creating a mask",
    "text": "Part 1: Find locations that experienced a blackout by creating a mask\nPsuedo code:\n\nLoad VIIRS night light data for two days to explore the data around the day of the storm. 2021-02-07 and 2021-02-16 provide two clear, contrasting images to visualize the extent of the power outage in Texas.\nCreate a raster object for each day with st_mosaic(). Houston lies on the border of two tiles (h08v05 and h08v06) produced by the NASA data products; therefore, we need to download these two files per date and mosaic them into one raster.\nFind the change in night light intensity between the two days by subtracting the Feb 07 mosaic raster (pre-blackout data) by the Feb 16 mosaic raster (post-blackout data). The difference in night light intensity will help identify the areas that experienced a blackout.\nReclassify the difference raster to create a “blackout mask”, assuming that any location that experienced a drop of more than 200 nW cm^-2 sr^-1 experienced a blackout. Assign NA values to the areas that did not experience a blackout (all locations that experienced a drop of less than 200 nW cm^-2 sr^-1 change).\nVectorize the blackout mask to create a polygon layer that can be used to identify the census tracts that experienced a blackout.\nCrop (spatially subset) the blackout mask to the Houston area as defined by the following coordinates: (-96.5, 29), (-96.5, 30.5), (-94.5, 30.5), (-94.5, 29). This was completed by the following steps: (1) define the bounding box for Houston using the coordinates provided; (2) create a polygon from the bounding box and make the polygon an sf object; (3) use a spatial subset to crop the blackout mask to the Houston area.\nRe-project the cropped blackout dataset to EPSG:3083 (NAD83 / Texas Centric Albers Equal Area)\n\n\nLoad data\n\n\nShow the code\n# h08v05 on 2021-02-07\nNL_0207_v05 &lt;- stars::read_stars(here(\"posts/2024-11-10-houston-blackout/data/VNP46A1/VNP46A1.A2021038.h08v05.001.2021039064328.tif\"))\n# h08v06 on 2021-02-07\nNL_0207_v06 &lt;- stars::read_stars(here(\"posts/2024-11-10-houston-blackout/data/VNP46A1/VNP46A1.A2021038.h08v06.001.2021039064329.tif\"))\n# h08v05 on 2021-02-16\nNL_0216_v05 &lt;- stars::read_stars(here(\"posts/2024-11-10-houston-blackout/data/VNP46A1/VNP46A1.A2021047.h08v05.001.2021048091106.tif\"))\n# h08v06 on 2021-02-16\nNL_0216_v06 &lt;- stars::read_stars(here(\"posts/2024-11-10-houston-blackout/data/VNP46A1/VNP46A1.A2021047.h08v06.001.2021048091105.tif\"))\n\n\n\n\nCreate a raster object for each day with terra::mosaic()\n\n\nShow the code\n# mosaic the raster objects for 2021-02-07\nNL_0207_mosaic &lt;- stars::st_mosaic(NL_0207_v05, NL_0207_v06)\n\n# mosaic the raster objects for 2021-02-16\nNL_0216_mosaic &lt;- stars::st_mosaic(NL_0216_v05, NL_0216_v06)\n\n\n\n\nMake a map showing the night light intensity for each day\n\n\nShow the code\ntmap_mode(\"plot\")\n\nmap1 &lt;- tm_graticules(lines = FALSE) +\ntm_shape(NL_0207_mosaic) + \n  tm_raster(breaks = c(0, 0.2, 1, 3, 5, 10, 100, 200, 10000, 100000), \n            palette = viridisLite::viridis(8), \n            title = \"Night light intensity (nW cm^-2sr^-1)\") + \n  tm_layout(legend.outside = TRUE,\n            main.title = \"2021-02-07\",\n            main.title.size = 1,\n            legend.outside.position = \"right\",\n            legend.text.size = 0.5, \n            legend.title.size = 1)\n\nmap2 &lt;- tm_graticules(lines = FALSE) +\ntm_shape(NL_0216_mosaic) +\n  tm_raster(breaks = c(0, 0.2, 1, 3, 5, 10, 100, 200, 10000, 100000), \n            palette = viridisLite::viridis(8), \n            title = \"Night light intensity (nW cm^-2sr^-1)\") + \n  tm_layout(legend.outside = TRUE,\n            main.title = \"2021-02-16\",\n            main.title.size = 1,\n            legend.outside.position = \"right\",\n            legend.text.size = 0.5, \n            legend.title.size = 1)\n\ntmap_arrange(map1, map2, nrow = 1)\n\n\n\n\n\n\n\n\nFigure 1: Night light intensity in Houston for 2021-02-07 and 2021-02-16. The color scale represents the night light intensity in nW cm^-2 sr^-1.\n\n\n\n\n\n\n\nFind the change in night light intensity between the two days\n\n\nShow the code\n# find the difference in night light intensity\nNL_diff &lt;- NL_0207_mosaic - NL_0216_mosaic\n\n\n\n\nReclassify the difference raster\n\n\nShow the code\n# assign NA values to areas that did not experience a blackout (&lt; 200 nW)\n# assume any location w/ a drop of more than 200 nW experienced a blackout\nNL_diff[NL_diff &lt; 200] &lt;- NA\n# plot(NL_diff)\n\n\n\n\nVectorize the blackout mask\n\n\nShow the code\n# vectorize the blackout mask\nblackout_mask_sf &lt;- st_as_sf(NL_diff) %&gt;% # convert from raster to vector\n  st_make_valid() # fix any invalid geometries \n\n\n\n\nQC1: Check for invalid geometries in the blackout mask\n\n\nShow the code\n# check for invalid geometries in the redlining data with testthat\nif(testthat::expect_true(all(st_is_valid(blackout_mask_sf)))) {\n  print(\"No invalid geometries in the blackout mask\")\n} else {\n  warning(\"There are invalid geometries in the blackout mask\")\n}\n\n\n[1] \"No invalid geometries in the blackout mask\"\n\n\n\n\nCrop the blackout mask to the Houston area\n\n\nShow the code\n# define the bounding box for Houston\nhouston_bbox &lt;- matrix(c(-96.5, 29, \n                         -96.5, 30.5, \n                         -94.5, 30.5, \n                         -94.5, 29, \n                         -96.5, 29), # last coordinate to close the polygon\n                       ncol = 2, byrow = TRUE)\n\n# create a polygon with the bbox list of coordinates\nhouston_polygon &lt;- st_polygon(list(houston_bbox))\n\n# make the polygon an sf object\nhouston_sf &lt;- st_sfc(houston_polygon, \n                     crs = crs(blackout_mask_sf)) # assign same CRS as bo mask \n\n# use a spatial subset to crop the blackout mask to the Houston area\nblackout_mask_houston &lt;- blackout_mask_sf[houston_sf, ]\n# plot(blackout_mask_houston)\n\n# re-project cropped blackout sf to EPSG:3083 (NAD83 / Texas Centric Albers Equal Area)\nblackout_mask_houston_3083 &lt;- st_transform(blackout_mask_houston, \n                                           crs = 3083)\ncrs(blackout_mask_houston_3083) #QC\n\n\n\n\nQC2: Make sure the spatial subset worked; are all the data points within the Houston area?\n\n\nShow the code\n# change the houston_sf to the same CRS as the blackout mask for the QC\nhouston_sf_QC &lt;- st_transform(houston_sf, \n                              crs(blackout_mask_houston_3083), \n                              quiet = TRUE)\n\n# check if all points are within the Houston area\nif(testthat::expect_true(all(st_intersects(blackout_mask_houston_3083, \n                                           houston_sf_QC)))) {\n  print(\"All points are within the Houston area!\")\n} else {\n  warning(\"STOP! Not all points are within the Houston area\")\n}\n\n\n[1] \"All points are within the Houston area!\""
  },
  {
    "objectID": "posts/2024-11-10-houston-blackout/index.html#part-2-exclude-highways-from-the-analysis",
    "href": "posts/2024-11-10-houston-blackout/index.html#part-2-exclude-highways-from-the-analysis",
    "title": "Investigating EJ implications of the Houston blackout",
    "section": "Part 2: Exclude highways from the analysis",
    "text": "Part 2: Exclude highways from the analysis\nBecause highways may have experienced changes in their night light intensities that are unrelated to the storm, we need to exlude any locations within 200m of all highways in the Houston areas.\nPseudocode:\n\nLoad the OpenStreetMap data for Houston and filter the OpenStreetMap data to only include highways. A cool query shared by Ruth was used in the st_read() function to only load the highways from the roads GPKG!\n\n2, Identify all areas within 200m of all highways with the st_buffer() function. Before using st_buffer(), I transformed the highways to the same CRS as the blackout mask (EPSG:3083) and checked the units of the CRS to make sure the buffer was correct.\n\nUse st_union() to combine all the highway buffers into one polygon.\nUse the st_difference() function to exclude the highways from the blackout mask. st_difference(x, y) creates a polygon of the area of x that is not in y (x being the blackout mask, and y being the highway buffer.\n\n\nLoad highways data\n\n\nShow the code\n# load the OpenStreetMap data for Houston\nhighways &lt;- st_read(here(\"posts/2024-11-10-houston-blackout/data/gis_osm_roads_free_1.gpkg/gis_osm_roads_free_1.gpkg\"), \n                    query = \"SELECT * FROM gis_osm_roads_free_1 WHERE fclass='motorway'\")\n\n\n\n\nIdentify all areas within 200m of all highways\n\n\nShow the code\n# put the highways into the same crs as the blackout mask\nhighways_3083 &lt;- st_transform(highways, \n                              crs(blackout_mask_houston_3083))\n\n# check the units of the crs\nst_crs(highways_3083)$units # meters!\n\n# buffer the highways by 200m\nhighways_buffer &lt;- st_buffer(highways_3083, \n                             dist = 200)\n\n# make sure the highways buffer is valid\nhighways_buffer &lt;- st_make_valid(highways_buffer) \n\n# combine all the highway buffers into one polygon\nhighways_buffer_union &lt;- st_union(highways_buffer)\n# plot(highways_buffer_union)\n\n# make sure the highways buffer is in the same CRS as the blackout mask\nhighways_buffer_union &lt;- st_transform(highways_buffer_union, \n                                      crs(blackout_mask_houston_3083))\n\n\n\n\nQC3: Make sure the blackout mask & highways buffer are in the same CRS\n\n\nShow the code\n# check if the blackout mask and highways buffer are in the same CRS\nif(st_crs(blackout_mask_houston_3083) == st_crs(highways_buffer_union)) {\n  print(\"Carry on! The blackout mask and highways buffer are in the same CRS\")\n} else {\n  warning(\"STOP! The blackout mask and highways buffer are not in the same CRS\")\n}\n\n\n[1] \"Carry on! The blackout mask and highways buffer are in the same CRS\"\n\n\n\n\nExclude the highways from the blackout mask using st_difference()\n\n\nShow the code\n# exclude the highways from the blackout mask\nblackout_mask_houston_no_highways &lt;- st_difference(blackout_mask_houston_3083, \n                                                   highways_buffer_union)"
  },
  {
    "objectID": "posts/2024-11-10-houston-blackout/index.html#part-3-identify-homes-that-experienced-blackouts-by-combining-the-locations-of-homes-and-blackouts",
    "href": "posts/2024-11-10-houston-blackout/index.html#part-3-identify-homes-that-experienced-blackouts-by-combining-the-locations-of-homes-and-blackouts",
    "title": "Investigating EJ implications of the Houston blackout",
    "section": "Part 3: Identify homes that experienced blackouts by combining the locations of homes and blackouts",
    "text": "Part 3: Identify homes that experienced blackouts by combining the locations of homes and blackouts\n\nLoad the OpenStreetMap data for homes\n\n\nShow the code\nhomes_query &lt;- \"SELECT * FROM gis_osm_buildings_a_free_1 WHERE (type IS NULL AND name IS NULL) OR type in ('residential', 'apartments', 'house', 'static_caravan', 'detached')\"\n\nhomes &lt;- st_read(here(\"posts/2024-11-10-houston-blackout/data/gis_osm_buildings_a_free_1.gpkg/gis_osm_buildings_a_free_1.gpkg\"), \n                 query = homes_query)\n\n# transform the crs to the same as the blackout mask\nhomes_3083 &lt;- st_transform(homes, \n                           crs(blackout_mask_houston_no_highways))\n# plot(homes_3083)\n\n\n\n\nQC4: Make sure the homes are in the same CRS as the blackout mask\n\n\nShow the code\n# check if the homes are in the same CRS as the blackout mask\nif(st_crs(homes_3083) == st_crs(blackout_mask_houston_no_highways)) {\n  print(\"Carry on! The homes are in the same CRS as the blackout mask\")\n} else {\n  warning(\"STOP! The homes are not in the same CRS as the blackout mask\")\n}\n\n\n[1] \"Carry on! The homes are in the same CRS as the blackout mask\"\n\n\n\n\nIdentify homes that overlap with areas that experienced blackouts\n\n\nShow the code\n# filter the homes that overlap with the blackout mask\nhomes_blackout &lt;- homes_3083 %&gt;% \n  st_filter(y = blackout_mask_houston_no_highways, .predicate = st_intersects)\n\n\nAccording to this analysis, there were an estimated 157,970 homes in Houston that lost power during the 2021 winter storm (see Figure 2 below). Homes were defined as any building that was classified as residential, apartments, house, static caravan, or detached in the OpenStreetMap buildings data.\n\n\nMake a map of homes in Houston that experienced blackouts\n\n\nShow the code\n# load the Houston county boundary for context \nhouston_counties &lt;- st_read(here(\"posts/2024-11-10-houston-blackout/data/houston_county_boundaries/houston-county-boundaries.shp\")) %&gt;% \n  st_transform(crs(blackout_mask_houston_no_highways))\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\ntm_graticules(lines = FALSE) +\ntm_shape(houston_counties) + \n  tm_polygons(col = \"NAME\", border.col = \"black\", \n              title = \"Surrounding County\", \n              palette = tmaptools::get_brewer_pal(\"Accent\", n = 13, \n                                                  plot = FALSE)) +\ntm_shape(homes_blackout, name = \"Homes\") +\n  tm_dots(col = \"black\", size = 0.1) + \n  tm_scale_bar(position = c(\"right\", \"bottom\")) + \n  tm_compass(position = c(0.85, 0.85), \n             size = 2) + \n  tm_layout(legend.outside = TRUE)\n\n\n\n\n\n\n\n\nFigure 2: Homes in the Houston metropolitan area that experienced blackouts during the 2021 winter storm. Homes, represented by the black dots, were defined as any building that was classified as residential, apartments, house, static caravan, or detached in the OpenStreetMap buildings data."
  },
  {
    "objectID": "posts/2024-11-10-houston-blackout/index.html#part-4-identify-the-census-tracts-likely-impacted-by-blackouts",
    "href": "posts/2024-11-10-houston-blackout/index.html#part-4-identify-the-census-tracts-likely-impacted-by-blackouts",
    "title": "Investigating EJ implications of the Houston blackout",
    "section": "Part 4: Identify the census tracts likely impacted by blackouts",
    "text": "Part 4: Identify the census tracts likely impacted by blackouts\nPseudocode:\n\nThe folder ACS_2019_5YR_TRACT_48.gdb is an ArcGIS “file geodatabase” that contains data from the US Census Bureaus American Community Survet for census tracts in 2019. We need to use the st_layers() function to list the layers in the file geodatabase and identify the layer that contains the census tract data.\nIncome data is stored in the X19_INCOME layer. Looking at the ACS metadata, we can see that the B19013e1 variable represents the median household income.\nThe geodatabase contains a layer holding the geometry information (ACS_2019_5YR_TRACT_48_TEXAS), separate from the layers holding the ACS attributes. We have to combine the geometry with the attributes to get a feature layer that sf can use. We used a left_join() to combine the geometry and income data by the GEOID_Data field.\nIdentify the census tracts that contain homes that experienced blackouts by using the st_filter() function with .predicate = st_intersects to filter the census tract geometries that intersect with the homes that experienced blackouts.\nMake a new column in the sf object containing all census tracts that identified each tract as either experiencing a blackout or not. Use this column to create a boxplot comparing the distribution of median household income in census tracts that experienced blackouts to those that did not.\n\n\nLoad the socio-economic data for Houston\n\n\nShow the code\n# load the ACS gbd layers\nst_layers(here(\"posts/2024-11-10-houston-blackout/data/ACS_2019_5YR_TRACT_48_TEXAS.gdb/ACS_2019_5YR_TRACT_48_TEXAS.gdb\"))\n\n# load in the geometries layer & assign the same CRS as the blackout mask\nacs_geometry &lt;- st_read(here(\"posts/2024-11-10-houston-blackout/data/ACS_2019_5YR_TRACT_48_TEXAS.gdb/ACS_2019_5YR_TRACT_48_TEXAS.gdb\"), \n                        layer = \"ACS_2019_5YR_TRACT_48_TEXAS\") %&gt;% \n  st_transform(crs(blackout_mask_houston_no_highways))\n\n# load in the income layer\nacs_income &lt;- st_read(here(\"posts/2024-11-10-houston-blackout/data/ACS_2019_5YR_TRACT_48_TEXAS.gdb/ACS_2019_5YR_TRACT_48_TEXAS.gdb\"), \n                      layer = \"X19_INCOME\")\n\n# select the median household income variable & GEOID\nacs_median_income &lt;- acs_income %&gt;% \n  select(med_income = B19013e1, GEOID_Data = GEOID)\n\n\n\n\nJoin the median household income to the census tract geometries by GEOID_Data\n\n\nShow the code\n# join the median household income to the census tract geometries\nacs_census_income &lt;- left_join(acs_geometry, acs_median_income, \n                               by = \"GEOID_Data\")\n\n\n\n\nIdentify census tracts that contained homes that experienced blackouts\n\n\nShow the code\n# filter the census tracts that contain homes that experienced blackouts\ncensus_tracts_blackout &lt;- acs_census_income %&gt;% \n  st_filter(y = homes_blackout, .predicate = st_intersects)\n\n# list the names of the census tracts that contain homes that experienced blackouts\ncencus_tract_list &lt;- unique(census_tracts_blackout$NAME)\n# cencus_tract_list\n\n# count the number of census tracts that contain homes that experienced blackouts\nnum_census_tracts &lt;- length(cencus_tract_list)\n\n\nAccording to this analysis, there were an estimated 756 census tracts in Houston that contained homes that lost power during the 2021 winter storm.\n\n\nMake a map of the census tracts that contained homes that experienced blackouts\n\n\nShow the code\n# make sure the census tract layer is in the same CRS as the blackout mask\nacs_census_income &lt;- st_transform(acs_census_income, \n                                  crs(blackout_mask_houston_no_highways))\n\n# mask the tract layer to Houston for map context\nfull_tract_layer &lt;- acs_census_income[houston_sf_QC, ]\n\n\n\n\nShow the code\ntmap_mode(\"plot\")\n\ntm_graticules(lines = FALSE) +\ntm_shape(full_tract_layer) + \n  tm_fill(col = \"grey\", alpha = 0.5, \n          showNA = FALSE) +\ntm_shape(census_tracts_blackout) + \n  tm_fill(col = \"med_income\", \n          style = \"cont\", \n          title = \"Median Household Income ($)\", \n          palette = viridisLite::plasma(5), \n          showNA = FALSE, \n          legend.reverse = TRUE) +\n  tm_compass(size = 2, \n             position = c(0.85, 0.1)) + \n  tm_scale_bar(position = c(0.6, 0.01)) +\n  tm_layout(legend.outside = TRUE)\n\n\n\n\n\n\n\n\nFigure 3: Census tracts in Houston containing homes that experienced a blackout during the 2021 winter storm. All grey areas represesent census tracts that did not experience blackouts. The color scale represents the median household income ($) in census tracts that experienced a blackout.\n\n\n\n\n\n\n\nMake a plot comparing the distribution of median household income in census tracts that experienced blackouts to those that did not experience blackouts\nThe census_tract_list object contains the census tracts that experienced blackouts. We can use this to create a new column in the full_tract_layer object that indicates whether or not a census tract experienced a blackout.\n\n\nShow the code\n# make a new layer of census tracts that did not experience blackouts\nfull_tract_layer &lt;- full_tract_layer %&gt;% \n  mutate(blackout = ifelse(NAME %in% cencus_tract_list, \"Yes\", \"No\"))\n\n\n\n\nShow the code\n# calculate the median income for census tracts that experienced blackouts and those that did not\nmedian_income_blackout &lt;- full_tract_layer %&gt;%\n  st_drop_geometry() %&gt;%\n  group_by(blackout) %&gt;%\n  summarise(med_income = median(med_income, na.rm = TRUE))\n\n# make a boxplot \nggplot(full_tract_layer, aes(x = blackout, y = med_income, fill = blackout)) + \n  geom_boxplot() + \n  scale_fill_manual(values = c(\"No\" = \"grey\", \"Yes\" = \"salmon\")) +\n  theme_bw() + \n  labs(x = \"Blackout\", \n       y = \"Median Household Income ($)\") + \n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nFigure 4: Distribution of median household income in census tracts that experienced blackouts compared to those that did not experience blackouts. The median income for census tracts that experienced blackouts was $60,415, while the median income for census tracts that did not experience blackouts was approximately $57,220."
  },
  {
    "objectID": "posts/2024-11-10-houston-blackout/index.html#reflection",
    "href": "posts/2024-11-10-houston-blackout/index.html#reflection",
    "title": "Investigating EJ implications of the Houston blackout",
    "section": "Reflection",
    "text": "Reflection\nThis analysis examined the impacts of the 2021 winter storms in the Houston metropolitan area. We estimated the number of homes that lost power between February 7th and 16th, and examined the relationship between median income levels of census tracts that were likely impacted by the blackout versus those that were not. The analysis found that an estimated 157,970 homes in the Houston metropolitan area lost power during the winter storm. These homes were distributed across 756 census tracts in the region. The median household income in census tracts that experienced blackouts was $60,415, compared to $57,220 in census tracts that did not experience blackouts.\nOne of the limitations of this analysis is that the VIIRS night lights data used to identify areas that experienced blackouts is not a perfect measure of power outages, and while its resolution is relatively granular, it’s still coarse enough that some areas might be “brighter” or “darker” than they truly were. Additionally, the analysis assumes that any location that experienced a drop in night light intensity of more than 200 nW cm^-2 sr^-1 experienced a blackout. This threshold was chosen somewhat arbitrarily and may not accurately capture all areas that lost power. Therefore, taking both of these limitations into account, there’s a chance we didn’t truly capture all homes/locations that experienced blackouts. However, this analysis provides a good estimate of the impacts of the 2021 winter storms in Houston."
  },
  {
    "objectID": "posts/2024-11-10-houston-blackout/index.html#acknowledgements",
    "href": "posts/2024-11-10-houston-blackout/index.html#acknowledgements",
    "title": "Investigating EJ implications of the Houston blackout",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis assignment was created and organized Ruth Oliver, an Assistant Professor at the Bren School and the instructor for EDS 223. EDS 223 (Geospatial Analysis & Remote Sensing) is offered in the Master of Environmental Data Science (MEDS) program at the Bren School."
  },
  {
    "objectID": "posts/2024-11-10-houston-blackout/index.html#links-to-data-sources",
    "href": "posts/2024-11-10-houston-blackout/index.html#links-to-data-sources",
    "title": "Investigating EJ implications of the Houston blackout",
    "section": "Links to data sources",
    "text": "Links to data sources\n\nGeofabrik OSM Data Extracts\nHouston County Boundaries\nOpenStreetMap\nU.S. Census Bureau’s ACS\nVisible Infrared Imaging Radiometer Suite (VIIRS)"
  },
  {
    "objectID": "posts/2024-11-10-houston-blackout/index.html#references",
    "href": "posts/2024-11-10-houston-blackout/index.html#references",
    "title": "Investigating EJ implications of the Houston blackout",
    "section": "References",
    "text": "References\nWikipedia. 2021. “2021 Texas power crisis.” Last modified October 2, 2021. https://en.wikipedia.org/wiki/2021_Texas_power_crisis."
  },
  {
    "objectID": "posts/2024-11-10-houston-blackout/index.html#github-repository",
    "href": "posts/2024-11-10-houston-blackout/index.html#github-repository",
    "title": "Investigating EJ implications of the Houston blackout",
    "section": "GitHub repository",
    "text": "GitHub repository\nLink to the GitHub repository for this analysis: houston-blackout-analysis"
  },
  {
    "objectID": "posts/2024-09-20-morro-prioritizr/index.html",
    "href": "posts/2024-09-20-morro-prioritizr/index.html",
    "title": "Informing reserve design in the Morro Bay Watershed",
    "section": "",
    "text": "This analysis is from an assignment in ESM 270 (Conservation Planning) at the Bren School of Environmental Science & Management at the University of California, Santa Barbara. The assignment focused on informing reserve design in the Morro Bay watershed prioritizing special status species. It was required to be limited to two pages, with a figure included, hence the brevity of the write-up. The analysis aimed to identify important planning units in the Morro Bay watershed to include in a conservation reserve under two different settings/problems: (1) considering species with any status in the watershed; (2) considering only endemic, endangered, or threatened species in the watershed."
  },
  {
    "objectID": "posts/2024-09-20-morro-prioritizr/index.html#overview",
    "href": "posts/2024-09-20-morro-prioritizr/index.html#overview",
    "title": "Informing reserve design in the Morro Bay Watershed",
    "section": "",
    "text": "This analysis is from an assignment in ESM 270 (Conservation Planning) at the Bren School of Environmental Science & Management at the University of California, Santa Barbara. The assignment focused on informing reserve design in the Morro Bay watershed prioritizing special status species. It was required to be limited to two pages, with a figure included, hence the brevity of the write-up. The analysis aimed to identify important planning units in the Morro Bay watershed to include in a conservation reserve under two different settings/problems: (1) considering species with any status in the watershed; (2) considering only endemic, endangered, or threatened species in the watershed."
  },
  {
    "objectID": "posts/2024-09-20-morro-prioritizr/index.html#background-problem",
    "href": "posts/2024-09-20-morro-prioritizr/index.html#background-problem",
    "title": "Informing reserve design in the Morro Bay Watershed",
    "section": "Background & Problem",
    "text": "Background & Problem\nLandscapes and reserves are complex socio-ecological systems with various interactions between socioeconomic dynamics, political and governance systems, and natural processes across spatial and temporal scales (Meyfroidt et al., 2022). Because of this, successful planning measures at large scales and the selection of the most important planning units are difficult. To design effective reserve networks that address systematic conservation planning problems holistically, it’s crucial to consider both ecological and social factors. One situation where this kind of analysis is required is the identification of priority parcels in a region to include in a conservation reserve."
  },
  {
    "objectID": "posts/2024-09-20-morro-prioritizr/index.html#approach",
    "href": "posts/2024-09-20-morro-prioritizr/index.html#approach",
    "title": "Informing reserve design in the Morro Bay Watershed",
    "section": "Approach",
    "text": "Approach\nPrioritizr is an R package that guides systematic reserve design and solves various conservation planning problems. Similar to Marxan, but with enhanced flexibility, speed, and reproducibility, it can be used to build a conservation problem, generate a prioritization setting, solve and evaluate it. It’s flexible in design with many different functions that can build and customize conservation planning problems and solutions in a variety of settings. This analysis employs prioritizr to solve a conservation planning problem in the Morro Bay watershed with the goal of identifying priority parcels in the region to include in a conservation reserve under two different settings/problems: (1) considering species with any status in the watershed; (2) considering only endemic, endangered, or threatened species in the watershed.\nFor both settings, the problem was set up in prioritizr with the same exact inputs other than the filtering of irreplaceable species. All data was obtained from a previous MESM group project focused on the Morro Bay estuary. Planning units were parcel data containing information on the unit id, cost, and status. It’s important to note that some units’ statuses were ‘locked in’ or ‘locked out’, meaning they either had to be included or could not be included in the reserve. Conservation features were defined by the three different settings of species mentioned above and the number of species in each planning unit. For each setting above, two problems were created: one that found the optimal solution, and another that created a portfolio of solutions that were within the top 15% of the optimal solution. After creating the portfolio of solutions, they were summed to examine the selection frequency of each parcel across all 100 runs, essentially identifying which planning units were most important to address the planning problem."
  },
  {
    "objectID": "posts/2024-09-20-morro-prioritizr/index.html#results",
    "href": "posts/2024-09-20-morro-prioritizr/index.html#results",
    "title": "Informing reserve design in the Morro Bay Watershed",
    "section": "Results",
    "text": "Results\nThe resulting planning units determined to be included/not included in the best solution under the setting with all species and the setting with only endemic, endangered, and threatened species are shown in Figure 1(A) and Figure 1(C) below, respectively. Under each setting, prioritized planning units appear to be the same for the most part; however, there are a couple of parcels throughout the watershed that were prioritized in Figure 1(A), but not in Figure 1(C). Figure 1(B) and Figure 1(D) portray the results of the summed portfolio solutions within the top 15% of the optimal solution in each setting across 100 runs, representing the parcels most important to address the planning problem. Similarly to Figure 1(A) and Figure 1(C), most of these planning units appear to be the same with all species and the selected species.\n\n\n\nFigure 1. Reserve design in the Morro Bay watershed under various scenarios. (A) Parcels either included (green) or not included (white dots) in the optimal reserve design solution including all species in the study. (B) Sum solutions showing the selection frequency of each planning unit across all model runs for all species in the study. (C) Parcels either included (green) or not included (white dots) in the optimal reserve design solution when considering only endemic, endangered, or threatened species occurring in the region. (D) Sum solutions showing the selection frequency of each planning unit across all model runs when considering only endemic, endangered, or threatened species occurring in the region."
  },
  {
    "objectID": "posts/2024-09-20-morro-prioritizr/index.html#conclusion",
    "href": "posts/2024-09-20-morro-prioritizr/index.html#conclusion",
    "title": "Informing reserve design in the Morro Bay Watershed",
    "section": "Conclusion",
    "text": "Conclusion\nUnder each setting/problem explored in this analysis, many of the same planning units were selected to include in the optimal solution and reserve design in the Morro Bay watershed. For the few parcels that were included in the setting with all species but not in the setting with endemic, endangered, or threatened species, it’s likely that these species are not known to occur across these units. However, due to reserve dynamics, spillover effects, and adverse, interconnected impacts across landscapes, that doesn’t necessarily mean that these parcels are not important to the conservation of these imperiled species. In an analysis like this striving to solve a specific conservation problem, it’s crucial to consider other aspects of equitable, inclusive conservation planning that are difficult to capture in maximization models. After prioritizing planning units for biodiversity and socioeconomic factors (or before this kind of analysis is done), it’s imperative to engage local communities and a diverse range of stakeholders and voices in the reserve design process."
  },
  {
    "objectID": "posts/2024-09-20-morro-prioritizr/index.html#acknowledgements",
    "href": "posts/2024-09-20-morro-prioritizr/index.html#acknowledgements",
    "title": "Informing reserve design in the Morro Bay Watershed",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis assignment was created and organized Ashley Larsen, an Associate Professor at the Bren School and the instructor for ESM 270. ESM 270 (Conservation Planning) is offered in the Master of Environmental Science & Management (MESM) program at the Bren School."
  },
  {
    "objectID": "posts/2024-09-20-morro-prioritizr/index.html#references",
    "href": "posts/2024-09-20-morro-prioritizr/index.html#references",
    "title": "Informing reserve design in the Morro Bay Watershed",
    "section": "References",
    "text": "References\nMeyfroidt, P., de Bremond, A., Ryan, C. M., Archer, E., Aspinall, R., Chhabra, A., Camara, G., Corbera, E., DeFries, R., Díaz, S., Dong, J., Ellis, E. C., Erb, K.-H., Fisher, J. A., Garrett, R. D., Golubiewski, N. E., Grau, H. R., Grove, J. M., Haberl, H., & Heinimann, A. (2022). Ten facts about land systems for sustainability. Proceedings of the National Academy of Sciences, 119(7), e2109217118. https://doi.org/10.1073/pnas.2109217118"
  },
  {
    "objectID": "posts/2024-09-10-bathy-dorian/index.html",
    "href": "posts/2024-09-10-bathy-dorian/index.html",
    "title": "Analyzing the impacts of hurricanes upon bathymetry",
    "section": "",
    "text": "CitationBibTeX citation:@online{pepperdine2024,\n  author = {Pepperdine, Maxwell},\n  title = {Analyzing the Impacts of Hurricanes Upon Bathymetry},\n  date = {2024-09-10},\n  url = {https://maxpepperdine.github.io/posts/2024-09-10-bathy-dorian/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPepperdine, Maxwell. 2024. “Analyzing the Impacts of Hurricanes\nUpon Bathymetry.” September 10, 2024. https://maxpepperdine.github.io/posts/2024-09-10-bathy-dorian/."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Maxwell Pepperdine",
    "section": "",
    "text": "Hi there! I’m Maxwell Pepperdine (no affiliation to the university) and I’m a current master’s student in Environmental Science and Management at the Bren School at UC Santa Barbara. Specializing in Conservation Planning with an emphasis in GIS and geospatial analysis, I hope to develop data-driven solutions to today’s critical environmental problems. I have a strong interest in data analysis, geospatial analysis, and GIS and am excited to apply these skills in the field of natural resource management and conservation planning.\nI graduated summa cum laude from California Polytechnic State University (Cal Poly), San Luis Obispo in June of 2023 with a B.S. in Environmental Management and Protection and double minors in Biology & Sustainable Environments. Growing up in Santa Cruz, CA, I was fortunate to be surrounded by incredible ocean and redwood ecosystems which fostered my admiration and affinity for the natural environment at an early age. Outside of work and school, I enjoy hiking, backpacking, playing disc golf, ocean photography and spending time with friends and family. Ocean photography was one of my favorite hobbies growing up. While I haven’t done much as of late, it’s something that I would love to get back in to at some point. A few of my favorite photos are shared below!\n\nExperienceEducationHonors & awardsOcean photographySome of my favorate places\n\n\nArnhold Environmental Graduate Fellow (Jun 2024 - present) | Environmental Markets Lab, (emLab), Santa Barbara, CA\nGraduate Teaching Assistant (Jan 2024 - present) | University of California, Santa Barbara\nRemote Sensing Research Assistant (Jun 2024 - Sep 2024) | Edge Hill University, Ormskirk, UK\nSpatial Conservation Planning Research Assistant (Dec 2023 - May 2024) | California Central Coast Joint Venture (C3JV), Santa Cruz, CA\n\n\nMaster of Environmental Science and Management (Expected Jun 2025) | Bren School of Environmental Science & Management, UCSB\nB.S. in Environmental Management and Protection (Jun 2023) | California Polytechnic State University (Cal Poly), San Luis Obispo\n\n\n2023 Environmental Engineering and Science Foundation (EESF) Scholarship Recipient\nPresidents Honor List (2020, 2021, 2022, 2023) | Cal Poly, San Luis Obispo to make the list, students must have a GPA of 3.5 or higher for every quarter of the academic year\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhite Sands National Park, New Mexico\n\n\n\n\n\n\n\nBentonite Hills, Utah\n\n\n\n\n\n\n\n\n\nWhite Sands National Park, New Mexico\n\n\n\n\n\n\n\nBentonite Hills, Utah"
  },
  {
    "objectID": "about.html#about-me",
    "href": "about.html#about-me",
    "title": "Maxwell Pepperdine",
    "section": "",
    "text": "Hi there! I’m Maxwell Pepperdine (no affiliation to the university) and I’m a current master’s student in Environmental Science and Management at the Bren School at UC Santa Barbara. Specializing in Conservation Planning with an emphasis in GIS and geospatial analysis, I hope to develop data-driven solutions to today’s critical environmental problems. I have a strong interest in data analysis, geospatial analysis, and GIS and am excited to apply these skills in the field of natural resource management and conservation planning.\nI graduated summa cum laude from California Polytechnic State University (Cal Poly), San Luis Obispo in June of 2023 with a B.S. in Environmental Management and Protection and double minors in Biology & Sustainable Environments. Growing up in Santa Cruz, CA, I was fortunate to be surrounded by incredible ocean and redwood ecosystems which fostered my admiration and affinity for the natural environment at an early age. Outside of work and school, I enjoy hiking, backpacking, playing disc golf, ocean photography and spending time with friends and family. Ocean photography was one of my favorite hobbies growing up. While I haven’t done much as of late, it’s something that I would love to get back in to at some point. A few of my favorite photos are shared below!\n\nExperienceEducationHonors & awardsOcean photographySome of my favorate places\n\n\nArnhold Environmental Graduate Fellow (Jun 2024 - present) | Environmental Markets Lab, (emLab), Santa Barbara, CA\nGraduate Teaching Assistant (Jan 2024 - present) | University of California, Santa Barbara\nRemote Sensing Research Assistant (Jun 2024 - Sep 2024) | Edge Hill University, Ormskirk, UK\nSpatial Conservation Planning Research Assistant (Dec 2023 - May 2024) | California Central Coast Joint Venture (C3JV), Santa Cruz, CA\n\n\nMaster of Environmental Science and Management (Expected Jun 2025) | Bren School of Environmental Science & Management, UCSB\nB.S. in Environmental Management and Protection (Jun 2023) | California Polytechnic State University (Cal Poly), San Luis Obispo\n\n\n2023 Environmental Engineering and Science Foundation (EESF) Scholarship Recipient\nPresidents Honor List (2020, 2021, 2022, 2023) | Cal Poly, San Luis Obispo to make the list, students must have a GPA of 3.5 or higher for every quarter of the academic year\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhite Sands National Park, New Mexico\n\n\n\n\n\n\n\nBentonite Hills, Utah\n\n\n\n\n\n\n\n\n\nWhite Sands National Park, New Mexico\n\n\n\n\n\n\n\nBentonite Hills, Utah"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Maxwell Pepperdine",
    "section": "",
    "text": "My name is Maxwell, and I created this personal website using Quarto to share a little bit about who I am and some of the projects I’ve worked on throughout my academic and professional experiences. I am a current master’s student in Environmental Science and Management at the Bren School of Environmental Science & Management who is passionate about finding data-driven solutions to today’s critical environmental problems."
  },
  {
    "objectID": "index.html#hello",
    "href": "index.html#hello",
    "title": "Maxwell Pepperdine",
    "section": "",
    "text": "My name is Maxwell, and I created this personal website using Quarto to share a little bit about who I am and some of the projects I’ve worked on throughout my academic and professional experiences. I am a current master’s student in Environmental Science and Management at the Bren School of Environmental Science & Management who is passionate about finding data-driven solutions to today’s critical environmental problems."
  },
  {
    "objectID": "index.html#professional-interests",
    "href": "index.html#professional-interests",
    "title": "Maxwell Pepperdine",
    "section": "Professional Interests",
    "text": "Professional Interests\nConservation planning | GIS | Geospatial analysis | Data analysis | Water resources management | Nature-based solutions | Remote sensing | Climate adaptation"
  },
  {
    "objectID": "index.html#skills",
    "href": "index.html#skills",
    "title": "Maxwell Pepperdine",
    "section": "Skills",
    "text": "Skills\nSoftware/Computer: Esri ArcGIS Products (Pro, Online, Field Maps), RStudio, Python, Microsoft Office (Word, Excel, PowerPoint), Google Earth Engine, QGIS, GitHub, Quarto\nWriting: Technical writing of scientific research manuscripts, policy memos, and CEQA and NEPA reports/assessments"
  },
  {
    "objectID": "index.html#recent-ongoing-projects",
    "href": "index.html#recent-ongoing-projects",
    "title": "Maxwell Pepperdine",
    "section": "Recent & Ongoing Projects",
    "text": "Recent & Ongoing Projects\nIntegrating climate adaptation strategies into forest management\nMapping suitable nesting habitat for marbled murrelets in the SCM"
  },
  {
    "objectID": "posts/2024-09-17-connectivity/index.html",
    "href": "posts/2024-09-17-connectivity/index.html",
    "title": "Exploring habitat connectivity between core areas in a Costa Rican landscape",
    "section": "",
    "text": "This analysis is from an assignment in ESM 270 (Conservation Planning) at the Bren School of Environmental Science & Management at the University of California, Santa Barbara. The assignment focused on modeling movement patterns and connectivity for the jaguar (Panthera onca) across southern Costa Rica with Circuitscape. It was required to be limited to two pages, with a figure included, hence the brevity of the write-up. The analysis aimed to identify important movement corridors and barriers between core areas in the Talamanca-Osa region of southern Costa Rica to support jaguar connectivity and continued movement across the landscape."
  },
  {
    "objectID": "posts/2024-09-17-connectivity/index.html#overview",
    "href": "posts/2024-09-17-connectivity/index.html#overview",
    "title": "Exploring habitat connectivity between core areas in a Costa Rican landscape",
    "section": "",
    "text": "This analysis is from an assignment in ESM 270 (Conservation Planning) at the Bren School of Environmental Science & Management at the University of California, Santa Barbara. The assignment focused on modeling movement patterns and connectivity for the jaguar (Panthera onca) across southern Costa Rica with Circuitscape. It was required to be limited to two pages, with a figure included, hence the brevity of the write-up. The analysis aimed to identify important movement corridors and barriers between core areas in the Talamanca-Osa region of southern Costa Rica to support jaguar connectivity and continued movement across the landscape."
  },
  {
    "objectID": "posts/2024-09-17-connectivity/index.html#background-problem",
    "href": "posts/2024-09-17-connectivity/index.html#background-problem",
    "title": "Exploring habitat connectivity between core areas in a Costa Rican landscape",
    "section": "Background & Problem",
    "text": "Background & Problem\nThroughout the last 100 years, southern Costa Rica has undergone significant agricultural expansion and urban development. This has had adverse impacts on many species occurring throughout the region, especially jaguars (Panthera onca) which are forest-dependent with wide home ranges and require large areas of undisturbed habitat; therefore, making them particularly vulnerable to fragmentation. Increasing fragmentation in this region has resulted in two disconnected jaguar populations. To reconnect them and support their continued persistence throughout the southern Costa Rican landscape, land managers and conservation practitioners need to understand the species’ movement patterns and barriers hindering movement connectivity."
  },
  {
    "objectID": "posts/2024-09-17-connectivity/index.html#approach",
    "href": "posts/2024-09-17-connectivity/index.html#approach",
    "title": "Exploring habitat connectivity between core areas in a Costa Rican landscape",
    "section": "Approach",
    "text": "Approach\nCircuitscape and Linkage Mapper were used to model connectivity across the study area in ArcGIS Pro v3.0. Circuitscape is a tool that treats landscapes as conductive surfaces, utilizing connections between random walk theory and electrical circuit theory to predict aspects of movement and connectivity between important patches of a landscape. This analysis employed three Linkage Mapper modules to analyze jaguar movement and connectivity between identified core areas in the Talamanca-Osa region of southern Costa Rica: Linkage Mapper, Pinchpoint Mapper, and Barrier Mapper. The core areas are 3 national parks in the region–Corcovado, Piedras Blancas, and La Amistad which was clipped to the study area.\nThe first step of the analysis was to map the least-cost corridors between the three core areas with Linkage Mapper using a cost-weighted distance (CWD) threshold of 20,000 m. This served to create a distribution of CWDs of the best route passing through each cell across the study area, with lower values being closer to the LCP and higher values being more costly/resistive. Next, Circuitscape was run using Pinchpoint Mapper to inject ‘electrical current’ into the core areas and facilitate its flow across the landscape between cores. This step was conducted twice, once with a CWD cutoff distance of 1,000,000 m to run Circuitscape across the entire resistance surface, and once with a CWD cutoff distance of 20,000 m to constrain current flow to the least-cost corridor. As implied in the tool’s name, flowing current concentrates in ‘pinch-points’, representing areas where jaguar movement is likely to be funneled through a narrow area. Lastly, the Barrier Mapper tool was used to identify important barriers running along and adjacent to the LCP. A barrier detection radius of 1000 m was used, detecting barriers up to 2 km across."
  },
  {
    "objectID": "posts/2024-09-17-connectivity/index.html#results",
    "href": "posts/2024-09-17-connectivity/index.html#results",
    "title": "Exploring habitat connectivity between core areas in a Costa Rican landscape",
    "section": "Results",
    "text": "Results\nResults of the Circuitscape and Linkage mapper analysis are shown in Figure 1 below. Figure 1(A) portrays the Circuitscape and Pinchpoint Mapper analysis with a CWD cutoff distance of 20,000 m to constrain current flow to the least-cost corridor defined in the first step of the analysis. Areas in red represent higher values and regions where the corridor is more constricted (and jaguar movement is concentrated), with green regions as lower values and less constricted areas. Pinchpoint Mapper was designed to run Circuitscape within identified least-cost corridors to map pinch-points within these areas; however, running this tool across an entire landscape can also provide valuable information regarding alternative movement routes and stepping stones. Figure 1(B) shows the result of the Barrier Mapper analysis. Again, red areas represent higher values that indicate barriers with the most significant effect on CWDs between core areas.\n\n\n\nFigure 1. Least-cost paths (LCP) and corridors connecting core areas for jaguars in the Talamanca-Osa region of southern Costa Rica. The top map shows the three core areas (Corcovado National Park in the southwest, Piedras Blancas National Park in the center, and La Amistad National Park in the northeast) with LCPs (white lines) connecting each core area. Figure 1(A) portrays the results of the pinch-point mapper analysis with a CWD cutoff distance of 20,000 m, with red areas representing higher values and places where the corridor surrounding the LCP is more constricted. Figure 1(B) shows the results of the barrier mapper analysis with a barrier detection radius of 1000 m. Again, red areas have higher values representing the strongest CWD effect between core areas, and more likely barriers to movement."
  },
  {
    "objectID": "posts/2024-09-17-connectivity/index.html#conclusion",
    "href": "posts/2024-09-17-connectivity/index.html#conclusion",
    "title": "Exploring habitat connectivity between core areas in a Costa Rican landscape",
    "section": "Conclusion",
    "text": "Conclusion\nThis analysis provides valuable insight into jaguar movement between 3 core areas in the Talamanca-Osa region of southern Costa Rica. The Circuitscape analysis identified pinch-points within the least-cost corridors connecting core areas (Figure 1(A)). These regions are extremely important for connectivity and ensuring continued movement by jaguars across the landscape. They represent locations where jaguar movement is likely to be funneled through more narrow areas and vulnerable regions where a loss or degradation of habitat might significantly alter or sever important movement linkages. Barriers surrounding LCPs with the strongest effect on CWDs between core areas also represent more vulnerable areas within the landscape (Figure 1(B)), and conservation planning efforts should be focused in these locations to improve connectivity in high resistance areas within identified corridors.\nOne important consideration that isn’t captured in this analysis is the impact that increased jaguar connectivity or habitat might have on surrounding rural subsistence farmers in the region. Throughout the modeling process and selection of regions to focus connectivity enhancement on, land managers and conservation practitioners should engage local community members and ensure a diverse range of voices are included to incorporate important socioeconomic dynamics of conservation planning."
  },
  {
    "objectID": "posts/2024-09-17-connectivity/index.html#acknowledgements",
    "href": "posts/2024-09-17-connectivity/index.html#acknowledgements",
    "title": "Exploring habitat connectivity between core areas in a Costa Rican landscape",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis assignment was created and organized Ashley Larsen, an Associate Professor at the Bren School and the instructor for ESM 270. ESM 270 (Conservation Planning) is offered in the Master of Environmental Science & Management (MESM) program at the Bren School."
  },
  {
    "objectID": "posts/2024-09-22-maxent-coral/index.html",
    "href": "posts/2024-09-22-maxent-coral/index.html",
    "title": "Mapping the distribution of native and invasive marine species in the Indo-Pacific region",
    "section": "",
    "text": "This analysis, completed by Zoe Zhou and I, is from an assignment in ESM 270 (Conservation Planning) at the Bren School of Environmental Science & Management at the University of California, Santa Barbara. The assignment focused on modeling the current and future distributions of the crown-of-thorns starfish (Acanthaster planci) and grape coral (Euphyllia cristata) in the eastern Indo-Pacific region using Maxent. It was required to be limited to two pages, with a figure included, hence the brevity of the write-up. The analysis aimed to visualize changes in the occurrence probability and geographical distribution of these species under current and future climate scenarios to delineate regions where active restoration plans could be implemented."
  },
  {
    "objectID": "posts/2024-09-22-maxent-coral/index.html#overview",
    "href": "posts/2024-09-22-maxent-coral/index.html#overview",
    "title": "Mapping the distribution of native and invasive marine species in the Indo-Pacific region",
    "section": "",
    "text": "This analysis, completed by Zoe Zhou and I, is from an assignment in ESM 270 (Conservation Planning) at the Bren School of Environmental Science & Management at the University of California, Santa Barbara. The assignment focused on modeling the current and future distributions of the crown-of-thorns starfish (Acanthaster planci) and grape coral (Euphyllia cristata) in the eastern Indo-Pacific region using Maxent. It was required to be limited to two pages, with a figure included, hence the brevity of the write-up. The analysis aimed to visualize changes in the occurrence probability and geographical distribution of these species under current and future climate scenarios to delineate regions where active restoration plans could be implemented."
  },
  {
    "objectID": "posts/2024-09-22-maxent-coral/index.html#background",
    "href": "posts/2024-09-22-maxent-coral/index.html#background",
    "title": "Mapping the distribution of native and invasive marine species in the Indo-Pacific region",
    "section": "Background",
    "text": "Background\nEcological restoration is the process of enhancing the recovery of natural ecosystems that have been degraded, damaged, or destroyed (SER, 2004). Among other reasons, restoration efforts are commonly employed to mitigate and repair damage caused by introduced or invasive species. One example of an invasive species is the crown-of-thorn starfish (Acanthaster planci) which is known to eat and decimate coral populations such as the grape coral (Euphyllia cristata) (Brodie et al., 2005). Before initiating restoration efforts, it’s important to conduct data-driven analyses to advance restoration planning and employ the most effective management actions."
  },
  {
    "objectID": "posts/2024-09-22-maxent-coral/index.html#approach",
    "href": "posts/2024-09-22-maxent-coral/index.html#approach",
    "title": "Mapping the distribution of native and invasive marine species in the Indo-Pacific region",
    "section": "Approach",
    "text": "Approach\nA maximum entropy (Maxent) model was used to predict changes in the occurrence distribution for the crown-of-thorns starfish (Acanthaster planci) and grape coral (Euphyllia cristata) based on key marine data layers. Our analysis aimed to accomplish two primary goals: (1) Visualize changes in the current and future occurrence probability and geographical distribution of the crown-of-thorns starfish (COTS) and grape coral in the eastern Indo-Pacific region; (2) Utilize information from the species distribution models to propose an active restoration plan in areas where the COTS and grape coral are likely to occur. Maxent was applied using the R package Wallace (v2.1.1), an R-based GUI application that offers a simple, reproducible approach for ecological modeling and niche/distribution modeling analyses (Kass et al., 2022).\nOccurrence data for each species was acquired from the Global Biodiversity Information Facility (GBIF). Marine environmental data were sourced from Bio-ORACLE, which provides essential oceanographic layers such as ocean temperature (mean, max, min), salinity, nitrate and phosphate concentrations, and pH, all at a resolution of 0.05 degrees (Tyberghein et al., 2012; Assis et al., 2024). These variables were chosen based on their relevance to marine species distribution (Brodie et al., 2005; Yasuda, 2018; Wang & Tabeta, 2023). To model future distribution, we used data from a moderate emission scenario (SSP3-7.0) for the decade 2020-2030. All marine environmental data were downloaded in NetCDF format and converted to GeoTIFFs using the terra package in R to ensure compatibility with Maxent.\nFor model evaluation, we used spatial partitioning with a 75:25 (training:testing) split. The Maxent model leveraged presence and background points to account for potential biases that may arise from using presence-only points (Merow, 2013). A linear-quadratic (LQ) feature class was used to balance model complexity and account for non-linear species-environment relationships. After developing the distribution models, we analyzed the results in ArcGIS Pro v3.0 to identify key areas for restoration."
  },
  {
    "objectID": "posts/2024-09-22-maxent-coral/index.html#results",
    "href": "posts/2024-09-22-maxent-coral/index.html#results",
    "title": "Mapping the distribution of native and invasive marine species in the Indo-Pacific region",
    "section": "Results",
    "text": "Results\nUnder current conditions, the Maxent models indicated a high probability of occurrence for both the crown-of-thorns starfish (CoTS) and grape coral along the coastal areas of Northern Australia. Grape coral also showed a concentrated distribution around the Natuna Islands in the South China Sea, where CoTS is not projected to occur (Figure 1 Bottom). Future projections suggest a shift in both species’ distributions to the northeastern coast of Australia, with a contraction across the broader Indo-Pacific (Figure 1B). Notably, the contraction appears more pronounced for CoTS than grape coral. Despite these changes, the northeastern coast remains a favorable habitat for both species, making it a critical focus for future conservation and management strategies. The model’s performance was strong, with an AUC of 0.9187 for the training data and 0.9024 for the validation data.\n\n\n\nFigure 1. Current (A) and Future (B) Distributions for Grape Coral and CoTS under a moderate emission scenario (SSP3-7.0). Moderate (50%-75%) to high (75%-100%) projected occurrence for CoTS is overlaid in yellow, highlighting areas where both species may overlap, and regions prone to CoTS outbreaks.\n\n\n\n\n\nFigure 2. Current (A) and future (B) projected occurrence distribution for the crown-of-thorn starfish in the eastern Indo-Pacific region. Higher probabilities of occurrence are shown in darker shades of green, signifying areas of higher habitat suitability. A general shift to lower occurrence probabilities in the future is evident throughout the study area."
  },
  {
    "objectID": "posts/2024-09-22-maxent-coral/index.html#conclusion",
    "href": "posts/2024-09-22-maxent-coral/index.html#conclusion",
    "title": "Mapping the distribution of native and invasive marine species in the Indo-Pacific region",
    "section": "Conclusion",
    "text": "Conclusion\nFor restoration efforts, the predicted overlap between CoTS and grape coral distributions offers essential insights. Despite CoTS being native to the Great Barrier Reef, their periodic population outbreaks—exacerbated by human activities—continue to pose a significant threat to coral ecosystems. Active management strategies, such as the ongoing Crown-of-Thorns Starfish Control Program on the Great Barrier Reef, play a pivotal role in mitigating CoTS outbreaks. However, the study has several caveats, such as the reliance on presence-only data and environmental layers that may not capture local habitat variability, as well as uncertainty in future projections based on a single emission scenario. Moreover, the model does not account for species interactions or local adaptations, which could affect the predicted distributions of both species."
  },
  {
    "objectID": "posts/2024-09-22-maxent-coral/index.html#acknowledgements",
    "href": "posts/2024-09-22-maxent-coral/index.html#acknowledgements",
    "title": "Mapping the distribution of native and invasive marine species in the Indo-Pacific region",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis assignment was created and organized Ashley Larsen, an Associate Professor at the Bren School and the instructor for ESM 270. ESM 270 (Conservation Planning) is offered in the Master of Environmental Science & Management (MESM) program at the Bren School."
  },
  {
    "objectID": "posts/2024-11-05-redlining-legacies/index.html",
    "href": "posts/2024-11-05-redlining-legacies/index.html",
    "title": "Exploring patterns of environmental justice in Los Angeles County",
    "section": "",
    "text": "Legacies of historical injustices are often reflected in present-day environmental injustices. One example of this is racial segregation in the United States, in which a long history of these injustices are still visible today. As part of the New Deal in the 1930’s, the Home Owners’ Loan Corporation (HOLC) classified neighborhoods based on their perceived safety or risk for mortgage lending (hereby refered to as ‘HOLC grade’). Thy used this ranking system (HOLC grades of A, B, C, D) to block access to loans for home ownership, delineating maps to indicate where mortgages and loans should not be invested. This practice, colloquially known as “redlining,” disproportionately affected communities of color and has had lasting impacts on the socio-economic and environmental conditions of these neighborhoods that are still evident today.\nThis analysis aims to explore the legacy of redlining in Los Angeles County by examining the distribution of environmental and biodiversity observations within each HOLC grade. The analysis will be divided into two parts:\n\nLegacy of redlining in current environmental (in)justice: This section will explore the relationship between HOLC grades and three environmental justice (EJ) screen variables in Los Angeles County: % low income, percentile for PM 2.5, and percentile for low life expectancy. The analysis will examine how the current conditions of these variables differ with the four HOLC grades.\nLegacy of redlining in biodiversity observations: This section will examine the distribution of bird observations from 2022 within each HOLC grade in Los Angeles County to explore how the distribution of biodiversity observations has been influenced by historical redlining practices."
  },
  {
    "objectID": "posts/2024-11-05-redlining-legacies/index.html#background",
    "href": "posts/2024-11-05-redlining-legacies/index.html#background",
    "title": "Exploring patterns of environmental justice in Los Angeles County",
    "section": "",
    "text": "Legacies of historical injustices are often reflected in present-day environmental injustices. One example of this is racial segregation in the United States, in which a long history of these injustices are still visible today. As part of the New Deal in the 1930’s, the Home Owners’ Loan Corporation (HOLC) classified neighborhoods based on their perceived safety or risk for mortgage lending (hereby refered to as ‘HOLC grade’). Thy used this ranking system (HOLC grades of A, B, C, D) to block access to loans for home ownership, delineating maps to indicate where mortgages and loans should not be invested. This practice, colloquially known as “redlining,” disproportionately affected communities of color and has had lasting impacts on the socio-economic and environmental conditions of these neighborhoods that are still evident today.\nThis analysis aims to explore the legacy of redlining in Los Angeles County by examining the distribution of environmental and biodiversity observations within each HOLC grade. The analysis will be divided into two parts:\n\nLegacy of redlining in current environmental (in)justice: This section will explore the relationship between HOLC grades and three environmental justice (EJ) screen variables in Los Angeles County: % low income, percentile for PM 2.5, and percentile for low life expectancy. The analysis will examine how the current conditions of these variables differ with the four HOLC grades.\nLegacy of redlining in biodiversity observations: This section will examine the distribution of bird observations from 2022 within each HOLC grade in Los Angeles County to explore how the distribution of biodiversity observations has been influenced by historical redlining practices."
  },
  {
    "objectID": "posts/2024-11-05-redlining-legacies/index.html#part-1-legacy-of-redlining-in-current-environmental-injustice",
    "href": "posts/2024-11-05-redlining-legacies/index.html#part-1-legacy-of-redlining-in-current-environmental-injustice",
    "title": "Exploring patterns of environmental justice in Los Angeles County",
    "section": "Part 1: Legacy of redlining in current environmental (in)justice",
    "text": "Part 1: Legacy of redlining in current environmental (in)justice\n\nLoad packages\n\n\nShow packages used in this analysis\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(here)\nlibrary(tmap)\nlibrary(kableExtra)\nlibrary(tmaptools)\nlibrary(leaflet)\nlibrary(patchwork)\n\n\n\n\nLoad data\n\n\nShow the code\n# redlining data \nholc_redlining &lt;- st_read(here(\"posts/2024-11-05-redlining-legacies/data/mapping-inequality/mapping-inequality-los-angeles.json\"))\nholc_redlining &lt;- holc_redlining %&gt;% \n  filter(st_is_valid(holc_redlining)) # remove invalid geometries\n\n# EJ screen data\nej_screen &lt;- st_read(here(\"posts/2024-11-05-redlining-legacies/data/ejscreen/EJSCREEN_2023_BG_StatePct_with_AS_CNMI_GU_VI.gdb\"))\nej_screen &lt;- ej_screen %&gt;% \n  filter(st_is_valid(ej_screen)) %&gt;% # remove invalid geometries\n  st_transform(crs = st_crs(holc_redlining)) # set same CRS as redlining data\n\n# filter EJ screen data to LA county\nej_screen_la &lt;- ej_screen %&gt;% \n  filter(STATE_NAME == \"California\" & CNTY_NAME == \"Los Angeles County\")\n\n# LA county boundary; sourced from City of Los Angeles Hub\nla_county &lt;- st_read(here(\"posts/2024-11-05-redlining-legacies/data/la_county_boundary/County_Boundary.shp\")) %&gt;% \n  st_transform(crs = st_crs(holc_redlining)) # set same CRS as redlining data\nla_county &lt;- la_county %&gt;%\n  filter(st_is_valid(la_county)) # remove invalid geometries\n\n\n\nQC #1: Are there any invalid geometries in the layers that will be used?\n\n\nShow the code\n# check for invalid geometries in the redlining data with testthat\nif(testthat::expect_true(all(st_is_valid(holc_redlining)))) {\n  print(\"No invalid geometries in the redlining data\")\n} else {\n  warning(\"There are invalid geometries in the redlining data\")\n}\n\n\n[1] \"No invalid geometries in the redlining data\"\n\n\n\n\nShow the code\n# check for invalid geometries in the EJ screen data\nif(testthat::expect_true(all(st_is_valid(ej_screen_la)))) {\n  print(\"No invalid geometries in the EJ screen data\")\n} else {\n  warning(\"There are invalid geometries in the EJ screen data\")\n}\n\n\n[1] \"No invalid geometries in the EJ screen data\"\n\n\n\n\n\nMake a map with tmap\n\n\nShow the map code\n# set plot mode to interactive to activate basemaps\ntmap_mode(\"view\")\n\n# make the map\ntm_basemap(\"Esri.WorldTopoMap\", alpha = 0.7) + # add a basemap\ntm_shape(holc_redlining, \n         name = \"Historical redlining\") +\n  tm_fill(col = \"grade\", palette = \"-RdYlBu\", # color by grade; reverse pal\n          title = \"HOLC Grade\") + # clean up the layer name\n  tm_borders() + \ntm_shape(la_county, \n         name = \"LA County boundary\") +\n  tm_borders(lwd = 1.5) + \n  tm_scale_bar(position = c(\"top\", \"right\")) \n\n\n\n\n\n\n\n\nFigure 1: Historical redlining neighborhoods in Los Angeles County. HOLC grades of A are represented in dark blue, B by light blue, C by yellow, and D by red. Areas with no HOLC grade, or ‘missing’ grades, are shown in grey. The Los Angeles County boundary is also portrayed with the black line to provide additional geospatial context. HOLC grade data was sourced from Nelson et al. (2023) and the LA County boundary was sourced from the City of Los Angeles GeoHub.\n\n\n\n\nShow the map code\n## commented out for interactive maps; the compass function doesn't work\n# tm_layout(legend.position = c(\"right\", \"bottom\")) +\n#   tm_compass(position = c(\"left\", \"bottom\"))\n\n\n\n\nDetermine the % of current census block groups within each HOLC grade\nPseudocode outline:\n\nCheck if the EJ screen and HOLC redlining data are in the same Coordinate Reference System (CRS) using st_crs(). If they are not in the same CRS, reproject one of the datasets to match the other.\nJoin the HOLC redlining data to the EJ screen data. In this step, I used a spatial join with st_join() because this joins based on geometries that intersect by default. st_join() also performs a left join by default, so this will keep all the EJ screen data which is already at the block group level and add the HOLC grade to each observation.\nCalculate the % census blocks groups within in HOLC grade (A, B, C, D). Group the data by HOLC grade using group_by() and then calculate the % of block groups in each grade. I used the n() function to count the number of block groups in each grade, and then calculated the % of block groups in each grade by dividing the count number by the sum of blocks counted.\nClean up the data and show the results in a table (Table 1 below).\n\n\nQC #2: Are the EJ screen and redlining data in the same CRS?\n\n\nShow the code\n# make sure the CRS of the EJ screen data and HOLC redlining are the same\nif(st_crs(ej_screen_la) == st_crs(holc_redlining)) {\n  print(\"The EJ screen and HOLC redlining data are in the same CRS\")\n} else {\n  warning(\"The EJ screen and HOLC redlining data are NOT in the same CRS\")\n}\n\n\n[1] \"The EJ screen and HOLC redlining data are in the same CRS\"\n\n\n\n\nCalculate the % of block groups within each HOLC grade\n\n\nShow the code\n# join the redlining data to the EJ screen data; left join by default\nej_screen_redlining &lt;- st_join(ej_screen_la, holc_redlining)\n\n# calculate the % of each HOLC grade in the EJ screen data\nej_screen_redlining_pct &lt;- ej_screen_redlining %&gt;%\n  group_by(grade) %&gt;% # group by HOLC grade\n  summarize(n = n()) %&gt;% # count the number of block groups in each grade\n  mutate(pct_grade = n / sum(n) * 100) # add new column of % block groups in each grade\n\n\n\n##### cleaning up the data for the table\n\n# rename some columns and drop the geometry column\nej_screen_redlining_pct_clean &lt;- ej_screen_redlining_pct %&gt;% \n  rename(\"HOLC Grade\" = grade) %&gt;% # make the column names cleaner\n  rename(\"% of Block Groups\" = pct_grade) %&gt;%\n  select(\"HOLC Grade\", \"% of Block Groups\") %&gt;% \n  st_drop_geometry() # drop the geometry column\n\n# change the NA value in the HOLC Grade column to \"None\"\n# if not an NA value, leave the value as is\nej_screen_redlining_pct_clean$`HOLC Grade` &lt;- \n  ifelse(is.na(ej_screen_redlining_pct_clean$`HOLC Grade`), \"None\", \n         ej_screen_redlining_pct_clean$`HOLC Grade`)\n\n# change the # of decimals in the % column to 2\nej_screen_redlining_pct_clean$`% of Block Groups` &lt;- \n  round(ej_screen_redlining_pct_clean$`% of Block Groups`, 2)\n\n\n\n\nMake a table to show the results\n\n\nShow the code\n# make a table of the % of each HOLC grade in the EJ screen data\nej_screen_redlining_pct_clean %&gt;%\n  kable() %&gt;%\n  kable_styling(position = \"center\", \n                row_label_position = \"c\") %&gt;% \n  kable_classic(full_width = F)\n\n\n\n\nTable 1: Percentage of current census block groups within each HOLC grade.\n\n\n\n\n\n\nHOLC Grade\n% of Block Groups\n\n\n\n\nA\n5.10\n\n\nB\n13.70\n\n\nC\n31.23\n\n\nD\n14.77\n\n\nNone\n35.19\n\n\n\n\n\n\n\n\n\n\n\n\n\nExplore conditions of different EJ Screen variables by HOLC grade\n\nQC #3: Are the EJ screen and redlining data still in the same CRS?\n\n\nShow the code\n# make sure the CRS of the EJ screen data and HOLC redlining are the same\nif(st_crs(ej_screen_la) == st_crs(holc_redlining)) {\n  print(\"The EJ screen and HOLC redlining data are in the same CRS\")\n} else {\n  warning(\"The EJ screen and HOLC redlining data are NOT in the same CRS\")\n}\n\n\n[1] \"The EJ screen and HOLC redlining data are in the same CRS\"\n\n\n\n\nOverview of analysis & variables\n\nAnalysis goal:\n\nThis analysis aims to explore the relationship between the Home Owners’ Loan Corporation (HOLC) grades and three EJ Screen variables in Los Angeles County. To examine how the current conditions of these variables in census block groups differ with the four HOLC grades, I calculated the mean of each variable within each HOLC grade. Figure 2 below shows the results of this analysis.\n\nVariables of interest:\n\n% low income (LOWINCPCT): Taken from the EPA EJ Screen documentation: “The percent of a block group’s population in households where the household income is less than or equal to twice the federal ‘poverty level.’”\nPercentile for PM 2.5 (P_PM25): Taken from the EPA EJ Screen documentation: “EJScreen presents PM2.5 concentrations using percentile rank, ranging from 0 (lowest) to 100 (highest).”\nPercentile for low life expectancy (P_LIFEEXPPCT): Taken from the EPA EJ Screen documentation: EJScreen presents life expectancy using percentile rank, ranging from 0 (lowest) to 100 (highest) low life expectancy. A higher percentile indicates a lower life expectancy.\n\n\n\n\nData wrangling\nSteps/Pseudocode outline:\n\nFilter the EJ Screen data to create three new data frames that contain the EJ Screen variables of interest in LA County: % low income (LOWINCPCT), percentile for PM 2.5 (P_PM25), and percentile for low life expectancy (P_LIFEEXPPCT)\nWith each of the three variables created, join the EJ Screen data to the HOLC redlining data. In this step, I again used a spatial join with st_join() because this joins based on geometries that intersect by default. st_join() also performs a left join by default, so this will keep all the EJ Screen data and add the HOLC grade to each observation.\nCalculate the mean of each variable for each HOLC grade. This is done by grouping the data by HOLC grade using group_by() and then calculating the mean of the variable of interest. I used the na.rm = TRUE argument in the mean() function to remove any NA values in the data.\nMake a set of figures to show the results, and then combine them into one with the patchwork package.\n\n\n\nShow the code\n## filter the EJ screen data to create three data frames, one for each variable\nej_screen_low_income &lt;- ej_screen_la %&gt;% \n  select(ID, LOWINCPCT) # % low income\n\nej_screen_pm25 &lt;- ej_screen_la %&gt;%\n  select(ID, P_PM25) # percentile for PM 2.5\n\nej_screen_life_exp &lt;- ej_screen_la %&gt;%\n  select(ID, P_LIFEEXPPCT) # percentile for low life expectancy\n\n\n## join the EJ screen data to the HOLC redlining data for each variable\nej_screen_redlining_low_income &lt;- st_join(ej_screen_low_income, holc_redlining)\n\nej_screen_redlining_pm25 &lt;- st_join(ej_screen_pm25, holc_redlining)\n\nej_screen_redlining_life_exp &lt;- st_join(ej_screen_life_exp, holc_redlining)\n\n\n#### calculate the mean of each variable for each HOLC grade ####\n\n# low income \nej_screen_redlining_low_income_mean &lt;- ej_screen_redlining_low_income %&gt;%\n  group_by(grade) %&gt;%\n  summarize(mean_low_income = mean(LOWINCPCT, na.rm = TRUE))\n# change NA value in the HOLC Grade column to \"None\"; same method as above\nej_screen_redlining_low_income_mean$grade &lt;- \n  ifelse(is.na(ej_screen_redlining_low_income_mean$grade), \"None\", \n         ej_screen_redlining_low_income_mean$grade)\n\n\n# PM 2.5\nej_screen_redlining_pm25_mean &lt;- ej_screen_redlining_pm25 %&gt;%\n  group_by(grade) %&gt;%\n  summarize(mean_pm25 = mean(P_PM25, na.rm = TRUE))\n# change NA value in the HOLC Grade column to \"None\"\nej_screen_redlining_pm25_mean$grade &lt;- \n  ifelse(is.na(ej_screen_redlining_pm25_mean$grade), \"None\", \n         ej_screen_redlining_pm25_mean$grade)\n\n\n# low life expectancy\nej_screen_redlining_life_exp_mean &lt;- ej_screen_redlining_life_exp %&gt;%\n  group_by(grade) %&gt;%\n  summarize(mean_life_exp = mean(P_LIFEEXPPCT, na.rm = TRUE))\n# change NA value in the HOLC Grade column to \"None\"\nej_screen_redlining_life_exp_mean$grade &lt;- \n  ifelse(is.na(ej_screen_redlining_life_exp_mean$grade), \"None\", \n         ej_screen_redlining_life_exp_mean$grade)\n\n\n\n\nMake a set of figures (one for each variable)\n\n\nShow the code\n# % low income figure \npct_low_income &lt;- ggplot(ej_screen_redlining_low_income_mean, \n                        aes(x = grade, y = mean_low_income, \n                            fill = grade)) +\n  geom_col(col = \"black\") +\n  labs(title = \" \",\n       x = \" \",\n       y = \"% low income\") +\n  scale_fill_manual(values = c(\"A\" = \"limegreen\", \n                               \"B\" = \"royalblue2\", \n                               \"C\" = \"gold\", \n                               \"D\" = \"firebrick3\", \n                               \"None\" = \"grey\")) +\n  theme_classic()\npct_low_income &lt;- pct_low_income + \n  theme(legend.position = \"none\")\n\n\n\n\nShow the code\n# PM 2.5 figure\npm25 &lt;- ggplot(ej_screen_redlining_pm25_mean, \n               aes(x = grade, y = mean_pm25, \n                   fill = grade)) +\n  geom_col(col = \"black\") +\n  labs(title = \" \",\n       x = \"HOLC Grade\",\n       y = \"percentile for PM 2.5\") +\n  scale_fill_manual(values = c(\"A\" = \"limegreen\", \n                               \"B\" = \"royalblue2\", \n                               \"C\" = \"gold\", \n                               \"D\" = \"firebrick3\", \n                               \"None\" = \"grey\")) +\n  theme_classic()\npm25 &lt;- pm25 +\n  theme(legend.position = \"none\")\n\n\n\n\nShow the code\n# low life expectancy figure\nlife_exp &lt;- ggplot(ej_screen_redlining_life_exp_mean, \n                   aes(x = grade, y = mean_life_exp, \n                       fill = grade)) +\n  geom_col(col = \"black\") +\n  labs(title = \" \",\n       x = \" \",\n       y = \"percentile for low life expectancy\") +\n  scale_fill_manual(values = c(\"A\" = \"limegreen\", \n                               \"B\" = \"royalblue2\", \n                               \"C\" = \"gold\", \n                               \"D\" = \"firebrick3\", \n                               \"None\" = \"grey\")) +\n  theme_classic()\nlife_exp &lt;- life_exp +\n  theme(legend.position = \"none\")\n\n\n\n\nCombine the three figures into one with patchwork\n\n\nShow the code\n# make a grid of the three figures\ncombined_figures &lt;- pct_low_income + pm25 + life_exp\ncombined_figures + plot_annotation(title = \"EJ Screen variables by HOLC grade\", \n                                   tag_levels = \"A\") # label figures A,B,C\n\n\n\n\n\n\n\n\nFigure 2: EJ Screen variables by HOLC grade. (A) % low income, (B) percentile for PM 2.5, (C) percentile for low life expectancy. All values represent the mean value of each EJ Screen variable by HOLC grade. Looking at the three figures, it is clear that areas with lower HOLC grades have higher % low income, higher PM 2.5 percentiles, and higher low life expectancy percentiles.\n\n\n\n\n\n\n\n\nInterpretation of Results\nLooking at the results of the analysis shown in Figure 2 above, it is clear that areas with lower HOLC grades (i.e., D) have higher % low income, higher percentiles for particulate matter 2.5, and higher percentiles for low life expectancy. This suggests that the legacy of redlining has had long lasting impacts on the socio-economic and environmental conditions of these neighborhoods, and that these present day environmental injustices reflect patterns of historical injustice. Given that that this analysis only explored 3 environmental and demographic variables, future research could expand on this analysis by examining additional information offered on EJ screen and exploring their conditions within different HOLC grades."
  },
  {
    "objectID": "posts/2024-11-05-redlining-legacies/index.html#part-2-legacy-of-redlining-in-biodiversity-observations",
    "href": "posts/2024-11-05-redlining-legacies/index.html#part-2-legacy-of-redlining-in-biodiversity-observations",
    "title": "Exploring patterns of environmental justice in Los Angeles County",
    "section": "Part 2: Legacy of redlining in biodiversity observations",
    "text": "Part 2: Legacy of redlining in biodiversity observations\n\nBackground\nA recent study by Ellis-Soto et al. (2023) found that historical redlining has influenced our observations of biodiversity along with the socio-economic and environmental conditions of communities. Looking across 195 US cities, they found that redlined neighborhoods remain the most under sampled areas for biodiversity. One reason that makes this disparity concerning is that conservation decisions and management actions are often made based on available observation data. This can lead to biased selection of locations for conservation, inequitable distribution of the many benefits that result from being adjacent or close to conservation projects, and incomplete representations of biodiversity.\nTo explore this further, this analysis will examine the distribution of bird observations from 2022 within each HOLC grade in Los Angeles County using publicly accessible data from Nelson et al. (2023) and the Global Biodiversity Information Facility (GBIF).\n\n\nLoad data\n\n\nShow the code\n# GBIF birds data\nbirds &lt;- st_read(here(\"posts/2024-11-05-redlining-legacies/data/gbif-birds-LA/gbif-birds-LA.shp\"))\nst_crs(birds) # WGS 84; same as HOLC redlining, but we should still check\n\n# filter to only include data from 2022 bc the assignment\n# asks to analyze observations from 2022\nbirds &lt;- birds %&gt;% \n  filter(year == 2022)\n\n\n\n\nQC #4: Are the GBIF birds data and redlining data in the same CRS?\n\n\nShow the code\n# make sure the CRS of the GBIF birds data and HOLC redlining are the same\nif(st_crs(birds) == st_crs(holc_redlining)) {\n  print(\"The GBIF birds data and HOLC redlining data are in the same CRS\")\n} else {\n  warning(\"The GBIF birds data and HOLC redlining data are NOT in the same CRS\")\n}\n\n\n[1] \"The GBIF birds data and HOLC redlining data are in the same CRS\"\n\n\n\n\nQC #5: Does the birds data only include observations from 2022?\n\n\nShow the code\n# check if the birds data only includes observations from 2022\nif(all(birds$year == 2022)) {\n  print(\"The GBIF birds data only includes observations from 2022\")\n} else {\n  warning(\"Stop! The GBIF birds data includes observations from other years\")\n}\n\n\n[1] \"The GBIF birds data only includes observations from 2022\"\n\n\n\n\nData wrangling\nSteps/Pseudocode outline:\n\nJoin the GBIF birds data with observations from 2022 to the HOLC redlining data. In this step, I again used a spatial join with st_join() because this joins based on geometries that intersect by default. st_join() also performs a left join by default, so this will keep all the GBIF birds data and add the HOLC grade to each observation.\nCalculate the percent of observations within each HOLC grade. This is done by grouping the data by HOLC grade using group_by() and then calculating the percent of observations in each grade. I used the n() function to count the number of observations in each grade and then calculated the percent of observations in each grade by dividing this number by the sum of observations.\nMake a figure to show the results.\n\n\n\nShow the code\n# join the HOLC redlining data to the GBIF birds data\nbirds_redlining &lt;- st_join(birds, holc_redlining)\n\n# calculate the % of observations within each HOLC grade\nbirds_redlining_pct &lt;- birds_redlining %&gt;%\n  group_by(grade) %&gt;%\n  summarize(n = n()) %&gt;% # count the number of observations in each grade\n  mutate(pct_grade = n / sum(n) * 100) # add new column of % obsvs. in each grade\n\n# change NA value in the HOLC Grade column to \"None\"; same method as above\nbirds_redlining_pct$grade &lt;- \n  ifelse(is.na(birds_redlining_pct$grade), \"None\", \n         birds_redlining_pct$grade)\n\n# change the # of decimals in the % column to 2\nbirds_redlining_pct$pct_grade &lt;- \n  round(birds_redlining_pct$pct_grade, 2)\n\n# make a new object without the None observations \nbirds_redlining_pct_no_none &lt;- birds_redlining_pct %&gt;% \n  filter(grade != \"None\")\n\n\n\n\nMake a two figures & combine them with patchwork\n\n\nShow the code\n# make a bar plot of the % of observations in each HOLC grade\nbirds_plot_none &lt;- ggplot(birds_redlining_pct, \n                     aes(x = grade, y = pct_grade, \n                         fill = grade)) +\n  geom_col(col = \"black\") +\n  labs(title = \" \",\n       x = \"HOLC Grade\",\n       y = \"% of Observations\") +\n  scale_fill_manual(values = c(\"A\" = \"limegreen\", \n                               \"B\" = \"royalblue2\", \n                               \"C\" = \"gold\", \n                               \"D\" = \"firebrick3\", \n                               \"None\" = \"grey\")) +\n  theme_classic()\nbirds_plot_none &lt;- birds_plot_none + \n  theme(legend.position = \"none\")\n\n# make a plot without the None category at the end\nbirds_plot &lt;- ggplot(birds_redlining_pct_no_none, \n                     aes(x = grade, y = pct_grade, \n                         fill = grade)) +\n  geom_col(col = \"black\") +\n  geom_text(aes(label = paste0(pct_grade, \"%\")), \n            position = position_stack(vjust = 1.05), \n            size = 3) +\n  labs(title = \" \",\n       x = \"HOLC Grade\",\n       y = \"% of Observations\") +\n  scale_fill_manual(values = c(\"A\" = \"limegreen\", \n                               \"B\" = \"royalblue2\", \n                               \"C\" = \"gold\", \n                               \"D\" = \"firebrick3\")) +\n  theme_classic()\nbirds_plot &lt;- birds_plot + \n  theme(legend.position = \"none\")\n\n\n\n\nShow the code\n# combine the two figures with patchwork\nbirds_plot_none + birds_plot + \n  plot_annotation(title = \"Percentage of bird observations within each HOLC grade\", \n                  tag_levels = \"A\") # number the figures \"A\", \"B\", and \"C\"\n\n\n\n\n\n\n\n\nFigure 3: Percentage of bird observations from 2022 within each HOLC grade. (A) Including ‘None’ category with observations that were not within redlined districts, (B) Excluding ‘None’ category to only show observations within redlined districts. Other than non-redlined areas, districts with a grade of C had the highest % of bird observations. However, there doesn’t appear to be a clear relationship between HOLC grade and bird observations. Observation data was sourced from the Global Biodiversity Information Facility (GBIF), including data only from 2022.\n\n\n\n\n\n\n\nInterpretation of Results\nEllis-Soto et al. (2023) found that redlining has shaped our observations and distribution of biodiveristy as well as the socio-economic and environmental conditions of communities. They showed that “historically redlined neigborhoods remain the most under sampled urban areas for bird biodiversity today.” While there isn’t a clear difference in the % of bird observations between HOLC grades, Figure 1(A) makes it clear that redlined neighborhoods are still under sampled for bird biodiversity. This aligns with the findings of Ellis-Soto et al. (2023) and suggests that the legacy of redlining has had lasting impacts on the distribution of biodiversity observations in Los Angeles County."
  },
  {
    "objectID": "posts/2024-11-05-redlining-legacies/index.html#acknowledgements",
    "href": "posts/2024-11-05-redlining-legacies/index.html#acknowledgements",
    "title": "Exploring patterns of environmental justice in Los Angeles County",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis assignment was created and organized Ruth Oliver, an Assistant Professor at the Bren School and the instructor for EDS 223. EDS 223 (Geospatial Analysis & Remote Sensing) is offered in the Master of Environmental Data Science (MEDS) program at the Bren School."
  },
  {
    "objectID": "posts/2024-11-05-redlining-legacies/index.html#references",
    "href": "posts/2024-11-05-redlining-legacies/index.html#references",
    "title": "Exploring patterns of environmental justice in Los Angeles County",
    "section": "References",
    "text": "References\nCity of Los Angeles GeoHub. (2020). County Boundary. https://geohub.lacity.org/datasets/county-boundary\nEllis-Soto, D., Chapman, M., & Locke, D. H. (2023). Historical redlining is associated with increasing geographical disparities in bird biodiversity sampling in the United States. Nature Human Behaviour, 1-9\nGBIF. (2022). Global Biodiversity Information Facility. https://www.gbif.org/\nNelson, K. R., Winling, L., Marciano, R., Connolly, N., “Mapping Inequality,” American Panorama, ed. Robert K. Nelson and Edward L. Ayers, accessed October 17, 2023, https://dsl.richmond.edu/panorama/redlining/\nUnited States Environmental Protection Agency. 2024 version. EJScreen. https://www.epa.gov/ejscreen"
  },
  {
    "objectID": "posts/2024-11-05-redlining-legacies/index.html#github-repository",
    "href": "posts/2024-11-05-redlining-legacies/index.html#github-repository",
    "title": "Exploring patterns of environmental justice in Los Angeles County",
    "section": "GitHub repository",
    "text": "GitHub repository\nLink to the GitHub repository for this analysis: redlining-legacies-LA"
  },
  {
    "objectID": "posts/2024-11-15-ml-landuse/index.html",
    "href": "posts/2024-11-15-ml-landuse/index.html",
    "title": "Applying supervised machine mearning to landuse cover in Santa Barbara, CA",
    "section": "",
    "text": "# install.packages(\"rpart\")\n# install.packages(\"rpart.plot\")"
  },
  {
    "objectID": "posts/2024-11-15-ml-landuse/index.html#install-new-packages",
    "href": "posts/2024-11-15-ml-landuse/index.html#install-new-packages",
    "title": "Applying supervised machine mearning to landuse cover in Santa Barbara, CA",
    "section": "",
    "text": "# install.packages(\"rpart\")\n# install.packages(\"rpart.plot\")"
  },
  {
    "objectID": "posts/2024-11-15-ml-landuse/index.html#load-packages",
    "href": "posts/2024-11-15-ml-landuse/index.html#load-packages",
    "title": "Applying supervised machine mearning to landuse cover in Santa Barbara, CA",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(sf) # vector data\nlibrary(terra) # raster data\nlibrary(here) # file path management\nlibrary(tidyverse)\nlibrary(rpart) # recursive partitioning and regression trees\nlibrary(rpart.plot) # plotting for rpart\nlibrary(tmap) # map making"
  },
  {
    "objectID": "posts/2024-11-15-ml-landuse/index.html#load-data",
    "href": "posts/2024-11-15-ml-landuse/index.html#load-data",
    "title": "Applying supervised machine mearning to landuse cover in Santa Barbara, CA",
    "section": "Load data",
    "text": "Load data\n\nLandsat\n\n# list files for each band, including the full file path\nfilelist &lt;- list.files(here::here(\"posts/2024-11-15-ml-landuse/data/landsat-data\"), \n                       full.names = TRUE)\n\n# read in and store as a raster stack\nlandsat &lt;- rast(filelist)\n\n# update layer names to match band\nnames(landsat) &lt;- c(\"blue\", \"green\", \"red\", \"NIR\", \"SWIR1\", \"SWIR2\")\n\n# plot true color image\nplotRGB(landsat, r = 3, g = 2, b = 1, stretch = \"lin\")\n\n\n\n\n\n\n\n\n\n\nStudy area\n\n# read in shapefile for southern portion of SB county\n# this is our study area which we'll perform classification in\nsb_county_south &lt;- st_read(here::here(\"posts/2024-11-15-ml-landuse/data/SB_county_south.shp\")) %&gt;% \n  st_transform(., crs = crs(landsat))\n\nReading layer `SB_county_south' from data source \n  `C:\\Users\\maxpe\\Documents\\Bren Courses\\EDS 296\\maxpepperdine.github.io\\posts\\2024-11-15-ml-landuse\\data\\SB_county_south.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1 feature and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -120.2327 ymin: 34.33603 xmax: -119.5757 ymax: 34.53716\nGeodetic CRS:  NAD83\n\n# plot the study area\ntm_shape(sb_county_south) + \n  tm_borders()"
  },
  {
    "objectID": "posts/2024-11-15-ml-landuse/index.html#prepare-data",
    "href": "posts/2024-11-15-ml-landuse/index.html#prepare-data",
    "title": "Applying supervised machine mearning to landuse cover in Santa Barbara, CA",
    "section": "Prepare data",
    "text": "Prepare data\n\nCrop & mask Landsat scene to study area\n\n# crop Landsat scene to the extent of the SB county shapefile\nlandsat_cropped &lt;- terra::crop(landsat, sb_county_south)\n\n# mask the raster to southern portion of SB county\nlandsat_masked &lt;- terra::mask(landsat_cropped, sb_county_south)\n\n# remove unnecessary object from environment\nrm(landsat, Sb_county_south, landsat_cropped)\n\nplotRGB(landsat_masked, r = 3, g = 2, b = 1, stretch = \"lin\")\n\n\n\n\n\n\n\n\n\n\nConvert Landsat values to reflectance\n\n# reclassify erroneous values as NA\nrcl &lt;- matrix(c(-Inf, 7273, NA,\n                 43636, Inf, NA), ncol = 3, byrow = TRUE)\n\nlandsat &lt;- terra::classify(landsat_masked, rcl = rcl)\n\n# adjust values based on scaling and additive factor\nlandsat &lt;- (landsat * 0.0000275 - 0.2) * 100\n\n# check values are 0 - 100\nsummary(landsat)\n\n      blue           green            red             NIR       \n Min.   : 1.11   Min.   : 0.74   Min.   : 0.00   Min.   : 0.23  \n 1st Qu.: 2.49   1st Qu.: 2.17   1st Qu.: 1.08   1st Qu.: 0.75  \n Median : 3.06   Median : 4.59   Median : 4.45   Median :14.39  \n Mean   : 3.83   Mean   : 5.02   Mean   : 4.92   Mean   :11.52  \n 3rd Qu.: 4.63   3rd Qu.: 6.76   3rd Qu.: 7.40   3rd Qu.:19.34  \n Max.   :39.42   Max.   :53.32   Max.   :56.68   Max.   :57.08  \n NA's   :39856   NA's   :39855   NA's   :39855   NA's   :39856  \n     SWIR1           SWIR2      \n Min.   : 0.10   Min.   : 0.20  \n 1st Qu.: 0.41   1st Qu.: 0.60  \n Median :13.43   Median : 8.15  \n Mean   :11.88   Mean   : 8.52  \n 3rd Qu.:18.70   3rd Qu.:13.07  \n Max.   :49.13   Max.   :48.07  \n NA's   :42892   NA's   :46809"
  },
  {
    "objectID": "posts/2024-11-15-ml-landuse/index.html#training-classifier",
    "href": "posts/2024-11-15-ml-landuse/index.html#training-classifier",
    "title": "Applying supervised machine mearning to landuse cover in Santa Barbara, CA",
    "section": "Training classifier",
    "text": "Training classifier\n\nLoad training data\n\n# read in and transform training data\ntraining_data &lt;- st_read(here::here( \"posts/2024-11-15-ml-landuse/data/trainingdata.shp\")) %&gt;%\n  st_transform(., crs = crs(landsat))\n\nReading layer `trainingdata' from data source \n  `C:\\Users\\maxpe\\Documents\\Bren Courses\\EDS 296\\maxpepperdine.github.io\\posts\\2024-11-15-ml-landuse\\data\\trainingdata.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 40 features and 2 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 215539.2 ymin: 3808948 xmax: 259927.3 ymax: 3823134\nProjected CRS: WGS 84 / UTM zone 11N\n\n\n\n\nExtract reflectance values\n\n# extract reflectance values at training sites\ntraining_data_values &lt;- terra::extract(landsat, training_data, df = TRUE)\n\n# convert training data to data frame\ntraining_data_attributes &lt;- training_data %&gt;%\n  st_drop_geometry()\n\n# join training data attributes and extracted reflectance values\nSB_training_data &lt;- left_join(training_data_values, training_data_attributes,\n                              by = c(\"ID\" = \"id\")) %&gt;%\n                    mutate(type = as.factor(type)) # convert landcover type to factor\n\n\n\nTrain the classifier\n\n# establish model formula\n# we're predicting landcover type based on reflectance values of these bands\nSB_formula &lt;- type ~ red + green + blue + NIR + SWIR1 + SWIR2\n\n# train decision tree\nSB_decision_tree &lt;- rpart(formula = SB_formula,\n                          data = SB_training_data,\n                          method = \"class\", # for performing a classification\n                          na.action = na.omit)\n\n# plot decision tree\nprp(SB_decision_tree)"
  },
  {
    "objectID": "posts/2024-11-15-ml-landuse/index.html#apply-classifier-to-classify-the-landsat-scene",
    "href": "posts/2024-11-15-ml-landuse/index.html#apply-classifier-to-classify-the-landsat-scene",
    "title": "Applying supervised machine mearning to landuse cover in Santa Barbara, CA",
    "section": "Apply classifier to classify the Landsat scene",
    "text": "Apply classifier to classify the Landsat scene\n\n# classify image based on decision tree\nSB_classification &lt;- terra::predict(landsat, \n                                    SB_decision_tree, \n                                    type = \"class\", \n                                    na.rm = TRUE)\n\n# inspect level to understand the order of classes in prediction\nlevels(SB_training_data$type)\n\n[1] \"green_vegetation\" \"soil_dead_grass\"  \"urban\"            \"water\"           \n\nlevels(SB_classification)\n\n[[1]]\n  value            class\n1     1 green_vegetation\n2     2  soil_dead_grass\n3     3            urban\n4     4            water"
  },
  {
    "objectID": "posts/2024-11-15-ml-landuse/index.html#make-a-map",
    "href": "posts/2024-11-15-ml-landuse/index.html#make-a-map",
    "title": "Applying supervised machine mearning to landuse cover in Santa Barbara, CA",
    "section": "Make a map!",
    "text": "Make a map!\n\n# plot results\ntm_shape(SB_classification) +\n  tm_raster(palette = c(\"#8DB580\", \"#F2DDA4\", \n                        \"#7E8987\", \"#6A8EAE\"), \n            labels = c(\"green vegetation\", \"soil/dead grass\", \n                       \"urban\", \"water\"), \n            title = \"Landcover type\") +\n  tm_layout(legend.outside = TRUE,\n            main.title = \"Santa Barbara Landcover\")"
  },
  {
    "objectID": "posts/2025-01-16-mamu-scm/index.html",
    "href": "posts/2025-01-16-mamu-scm/index.html",
    "title": "Mapping suitable nesting habitat for an endangered bird in the SCM",
    "section": "",
    "text": "CitationBibTeX citation:@online{pepperdine2025,\n  author = {Pepperdine, Maxwell},\n  title = {Mapping Suitable Nesting Habitat for an Endangered Bird in\n    the {SCM}},\n  date = {2025-01-16},\n  url = {https://maxpepperdine.github.io/posts/2025-01-16-mamu-scm/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPepperdine, Maxwell. 2025. “Mapping Suitable Nesting Habitat for\nan Endangered Bird in the SCM.” January 16, 2025. https://maxpepperdine.github.io/posts/2025-01-16-mamu-scm/."
  }
]